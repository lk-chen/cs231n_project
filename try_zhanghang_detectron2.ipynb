{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cython in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (0.29.17)\n",
      "Requirement already satisfied: pyyaml==5.1 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (5.1)\n",
      "1.5.0 True\n",
      "gcc (Debian 8.3.0-28) 8.3.1 20200203\n",
      "Copyright (C) 2018 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# steps: https://github.com/lk-chen/detectron2-ResNeSt/blob/resnest/INSTALL.md\n",
    "\n",
    "!pip3 install cython pyyaml==5.1\n",
    "# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///usr/local/google/home/lkchen/cs231n/cs231n_project/detectron2-ResNeSt\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from detectron2==0.1.1) (6.2.1)\n",
      "Collecting cloudpickle (from detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/a5/bb99276ec2685e11d34e4aefc0d9238626843ea51f974aa59c68317d34b2/cloudpickle-1.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from detectron2==0.1.1) (0.18.2)\n",
      "Collecting fvcore==0.1.dev200407 (from detectron2==0.1.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/cf/44ee654b1322919b727c42c2ce0888aed5ab6492e90862e6679fb5b4b618/fvcore-0.1.dev200407.tar.gz\n",
      "Requirement already satisfied: matplotlib in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from detectron2==0.1.1) (3.2.1)\n",
      "Collecting pydot (from detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Collecting tabulate (from detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n",
      "Collecting tensorboard (from detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/fd/4f3ca1516cbb3713259ef229abd9314bba0077ef6070285dde0dd1ed21b2/tensorboard-2.2.1-py3-none-any.whl\n",
      "Collecting termcolor>=1.1 (from detectron2==0.1.1)\n",
      "Collecting tqdm>4.29.0 (from detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl\n",
      "Collecting yacs>=0.1.6 (from detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from fvcore==0.1.dev200407->detectron2==0.1.1) (1.18.2)\n",
      "Collecting portalocker (from fvcore==0.1.dev200407->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from fvcore==0.1.dev200407->detectron2==0.1.1) (5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/lib/python3/dist-packages (from matplotlib->detectron2==0.1.1) (2.4.6)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.24.3 (from tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/f1/23/62d3e82fa4c505f3195315c8a774b2e656b556d174329aa98edb829e48bc/grpcio-1.29.0.tar.gz\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard->detectron2==0.1.1) (44.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (2.21.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorboard->detectron2==0.1.1) (0.33.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (3.11.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (1.12.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/51/cd/a0c1f9e4582ea64dddf76c1b808b318d01e3b858a51c715bffab1016ecc7/tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/83/72/479a993ffb2a713419741278863db7d5aa995ff0e66dd354a8c38be3ff4f/google_auth-1.14.3-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (2019.11.28)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.1) (0.23)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (0.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/google/home/lkchen/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (4.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.1) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.1) (0.6.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (0.4.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.1.1) (7.2.0)\n",
      "Building wheels for collected packages: fvcore, grpcio, absl-py\n",
      "  Running setup.py bdist_wheel for fvcore ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /usr/local/google/home/lkchen/.cache/pip/wheels/0a/78/7a/85cd228669b8c0db682b13f7f34589b7351281111e6002a7cc\n",
      "  Running setup.py bdist_wheel for grpcio ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /usr/local/google/home/lkchen/.cache/pip/wheels/ed/06/79/e559ab3b10134903b88e2df2df1b7cc4d3f1a92a46972a09fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /usr/local/google/home/lkchen/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "Successfully built fvcore grpcio absl-py\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.14.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 5.2.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: cloudpickle, portalocker, tabulate, termcolor, tqdm, yacs, fvcore, pydot, requests-oauthlib, google-auth, google-auth-oauthlib, grpcio, absl-py, markdown, tensorboard-plugin-wit, werkzeug, tensorboard, detectron2\n",
      "\u001b[33m  The script tabulate is installed in '/usr/local/google/home/lkchen/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  The script tqdm is installed in '/usr/local/google/home/lkchen/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Found existing installation: google-auth 1.4.2\n",
      "    Uninstalling google-auth-1.4.2:\n",
      "      Successfully uninstalled google-auth-1.4.2\n",
      "\u001b[33m  The script google-oauthlib-tool is installed in '/usr/local/google/home/lkchen/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  The script markdown_py is installed in '/usr/local/google/home/lkchen/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  The script tensorboard is installed in '/usr/local/google/home/lkchen/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Running setup.py develop for detectron2\n",
      "Successfully installed absl-py-0.9.0 cloudpickle-1.4.1 detectron2 fvcore-0.1.dev200407 google-auth-1.14.3 google-auth-oauthlib-0.4.1 grpcio-1.29.0 markdown-3.2.2 portalocker-1.7.0 pydot-1.4.1 requests-oauthlib-1.3.0 tabulate-0.8.7 tensorboard-2.2.1 tensorboard-plugin-wit-1.6.0.post3 termcolor-1.1.0 tqdm-4.46.0 werkzeug-1.0.1 yacs-0.1.7\n"
     ]
    }
   ],
   "source": [
    "!(cd detectron2-ResNeSt && python3 -m pip install -e .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Args: Namespace(config_file='configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml', dist_url='tcp://127.0.0.1:60904', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)\n",
      "\u001b[32m[05/16 11:24:13 detectron2:104]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[05/16 11:24:13 detectron2:105]: \u001b[0mEnvironment info:\n",
      "------------------------  ----------------------------------------------------------------------------------------\n",
      "sys.platform              linux\n",
      "Python                    3.7.7 (default, Mar 10 2020, 13:18:53) [GCC 9.2.1 20191109]\n",
      "numpy                     1.18.2\n",
      "detectron2                0.1.1 @/usr/local/google/home/lkchen/cs231n/cs231n_project/detectron2-ResNeSt/detectron2\n",
      "detectron2 compiler       GCC 9.2\n",
      "detectron2 CUDA compiler  10.2\n",
      "detectron2 arch flags     sm_52\n",
      "DETECTRON2_ENV_MODULE     <not set>\n",
      "PyTorch                   1.5.0 @/usr/local/google/home/lkchen/.local/lib/python3.7/site-packages/torch\n",
      "PyTorch debug build       False\n",
      "CUDA available            True\n",
      "GPU 0                     Quadro M2000\n",
      "CUDA_HOME                 /usr/local/cuda\n",
      "NVCC                      Cuda compilation tools, release 10.2, V10.2.89\n",
      "Pillow                    6.2.1\n",
      "torchvision               0.6.0 @/usr/local/google/home/lkchen/.local/lib/python3.7/site-packages/torchvision\n",
      "torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\n",
      "cv2                       4.2.0\n",
      "------------------------  ----------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[05/16 11:24:13 detectron2:107]: \u001b[0mCommand line arguments: Namespace(config_file='configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml', dist_url='tcp://127.0.0.1:60904', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)\n",
      "\u001b[32m[05/16 11:24:13 detectron2:111]: \u001b[0mContents of args.config_file=configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml:\n",
      "_BASE_: \"../Base-RCNN-C4.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 128\n",
      "    NUM_CLASSES: 10\n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TEST: 800\n",
      "DATASETS:\n",
      "  TRAIN: ('voc_2012_trainval',)\n",
      "  TEST: ('voc_2012_test',)\n",
      "SOLVER:\n",
      "  STEPS: (12000, 16000)\n",
      "  MAX_ITER: 2000\n",
      "  WARMUP_ITERS: 100\n",
      "  BASE_LR: 0.001\n",
      "  GAMMA: 0.01\n",
      "  IMS_PER_BATCH: 2\n",
      "\n",
      "\u001b[32m[05/16 11:24:13 detectron2:115]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('voc_2012_test',)\n",
      "  TRAIN: ('voc_2012_trainval',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 64, 128, 256, 512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: []\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    AVD: False\n",
      "    AVG_DOWN: False\n",
      "    BOTTLENECK_WIDTH: 64\n",
      "    DEEP_STEM: False\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res4']\n",
      "    RADIX: 1\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 128\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 10\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.01\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 2000\n",
      "  MOMENTUM: 0.9\n",
      "  STEPS: (12000, 16000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 100\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 11:24:13 detectron2:122]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[05/16 11:24:13 d2.utils.env:29]: \u001b[0mUsing a generated random seed 14119286\n",
      "\u001b[32m[05/16 11:24:16 d2.engine.defaults:399]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): SplAtConv2d(\n",
      "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
      "          (bn0): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (rsoftmax): rSoftMax()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): SplAtConv2d(\n",
      "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
      "          (bn0): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (rsoftmax): rSoftMax()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): SplAtConv2d(\n",
      "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
      "          (bn0): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (bn1): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (rsoftmax): rSoftMax()\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 11:24:17 d2.data.build:63]: \u001b[0mRemoved 0 images with no usable annotations. 5415 images left.\n",
      "\u001b[32m[05/16 11:24:17 d2.data.build:164]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|      car      | 20609        |    van     | 2407         |   truck    | 965          |\n",
      "|  pedestrian   | 0            |   person   | 2477         |  cyclist   | 1042         |\n",
      "|     tram      | 511          |    misc    | 877          |  dontcare  | 8373         |\n",
      "| person_sitt.. | 222          |            |              |            |              |\n",
      "|     total     | 37483        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[05/16 11:24:17 d2.data.common:88]: \u001b[0mSerializing 5415 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/16 11:24:17 d2.data.common:95]: \u001b[0mSerialized dataset takes 3.53 MiB\n",
      "\u001b[32m[05/16 11:24:17 d2.data.detection_utils:464]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/16 11:24:17 d2.data.build:307]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[05/16 11:24:17 fvcore.common.checkpoint:98]: \u001b[0mLoading checkpoint from detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
      "\u001b[32m[05/16 11:24:17 fvcore.common.file_io:496]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/ImageNetPretrained/MSRA/R-50.pkl cached in /usr/local/google/home/lkchen/.torch/fvcore_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:80]: \u001b[0mRemapping C2 weights ......\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv1.norm.bias                      loaded from res2_0_branch2a_bn_beta           of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv1.norm.running_mean              loaded from res2_0_branch2a_bn_running_mean   of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv1.norm.running_var               loaded from res2_0_branch2a_bn_running_var    of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv1.norm.weight                    loaded from res2_0_branch2a_bn_gamma          of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv1.weight                         loaded from res2_0_branch2a_w                 of shape (64, 64, 1, 1)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv2.norm.bias                      loaded from res2_0_branch2b_bn_beta           of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv2.norm.running_mean              loaded from res2_0_branch2b_bn_running_mean   of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv2.norm.running_var               loaded from res2_0_branch2b_bn_running_var    of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv2.norm.weight                    loaded from res2_0_branch2b_bn_gamma          of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv2.weight                         loaded from res2_0_branch2b_w                 of shape (64, 64, 3, 3)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv3.norm.bias                      loaded from res2_0_branch2c_bn_beta           of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv3.norm.running_mean              loaded from res2_0_branch2c_bn_running_mean   of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv3.norm.running_var               loaded from res2_0_branch2c_bn_running_var    of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv3.norm.weight                    loaded from res2_0_branch2c_bn_gamma          of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.conv3.weight                         loaded from res2_0_branch2c_w                 of shape (256, 64, 1, 1)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.shortcut.norm.bias                   loaded from res2_0_branch1_bn_beta            of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.shortcut.norm.running_mean           loaded from res2_0_branch1_bn_running_mean    of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.shortcut.norm.running_var            loaded from res2_0_branch1_bn_running_var     of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.shortcut.norm.weight                 loaded from res2_0_branch1_bn_gamma           of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.0.shortcut.weight                      loaded from res2_0_branch1_w                  of shape (256, 64, 1, 1)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv1.norm.bias                      loaded from res2_1_branch2a_bn_beta           of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv1.norm.running_mean              loaded from res2_1_branch2a_bn_running_mean   of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv1.norm.running_var               loaded from res2_1_branch2a_bn_running_var    of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv1.norm.weight                    loaded from res2_1_branch2a_bn_gamma          of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv1.weight                         loaded from res2_1_branch2a_w                 of shape (64, 256, 1, 1)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv2.norm.bias                      loaded from res2_1_branch2b_bn_beta           of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv2.norm.running_mean              loaded from res2_1_branch2b_bn_running_mean   of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv2.norm.running_var               loaded from res2_1_branch2b_bn_running_var    of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv2.norm.weight                    loaded from res2_1_branch2b_bn_gamma          of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv2.weight                         loaded from res2_1_branch2b_w                 of shape (64, 64, 3, 3)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv3.norm.bias                      loaded from res2_1_branch2c_bn_beta           of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv3.norm.running_mean              loaded from res2_1_branch2c_bn_running_mean   of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv3.norm.running_var               loaded from res2_1_branch2c_bn_running_var    of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv3.norm.weight                    loaded from res2_1_branch2c_bn_gamma          of shape (256,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.1.conv3.weight                         loaded from res2_1_branch2c_w                 of shape (256, 64, 1, 1)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv1.norm.bias                      loaded from res2_2_branch2a_bn_beta           of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv1.norm.running_mean              loaded from res2_2_branch2a_bn_running_mean   of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv1.norm.running_var               loaded from res2_2_branch2a_bn_running_var    of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv1.norm.weight                    loaded from res2_2_branch2a_bn_gamma          of shape (64,)\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv1.weight                         loaded from res2_2_branch2a_w                 of shape (64, 256, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv2.norm.bias                      loaded from res2_2_branch2b_bn_beta           of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv2.norm.running_mean              loaded from res2_2_branch2b_bn_running_mean   of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv2.norm.running_var               loaded from res2_2_branch2b_bn_running_var    of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv2.norm.weight                    loaded from res2_2_branch2b_bn_gamma          of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv2.weight                         loaded from res2_2_branch2b_w                 of shape (64, 64, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv3.norm.bias                      loaded from res2_2_branch2c_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv3.norm.running_mean              loaded from res2_2_branch2c_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv3.norm.running_var               loaded from res2_2_branch2c_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv3.norm.weight                    loaded from res2_2_branch2c_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res2.2.conv3.weight                         loaded from res2_2_branch2c_w                 of shape (256, 64, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv1.norm.bias                      loaded from res3_0_branch2a_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv1.norm.running_mean              loaded from res3_0_branch2a_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv1.norm.running_var               loaded from res3_0_branch2a_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv1.norm.weight                    loaded from res3_0_branch2a_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv1.weight                         loaded from res3_0_branch2a_w                 of shape (128, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv2.norm.bias                      loaded from res3_0_branch2b_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv2.norm.running_mean              loaded from res3_0_branch2b_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv2.norm.running_var               loaded from res3_0_branch2b_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv2.norm.weight                    loaded from res3_0_branch2b_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv2.weight                         loaded from res3_0_branch2b_w                 of shape (128, 128, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv3.norm.bias                      loaded from res3_0_branch2c_bn_beta           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv3.norm.running_mean              loaded from res3_0_branch2c_bn_running_mean   of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv3.norm.running_var               loaded from res3_0_branch2c_bn_running_var    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv3.norm.weight                    loaded from res3_0_branch2c_bn_gamma          of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.conv3.weight                         loaded from res3_0_branch2c_w                 of shape (512, 128, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.shortcut.norm.bias                   loaded from res3_0_branch1_bn_beta            of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.shortcut.norm.running_mean           loaded from res3_0_branch1_bn_running_mean    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.shortcut.norm.running_var            loaded from res3_0_branch1_bn_running_var     of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.shortcut.norm.weight                 loaded from res3_0_branch1_bn_gamma           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.0.shortcut.weight                      loaded from res3_0_branch1_w                  of shape (512, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv1.norm.bias                      loaded from res3_1_branch2a_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv1.norm.running_mean              loaded from res3_1_branch2a_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv1.norm.running_var               loaded from res3_1_branch2a_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv1.norm.weight                    loaded from res3_1_branch2a_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv1.weight                         loaded from res3_1_branch2a_w                 of shape (128, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv2.norm.bias                      loaded from res3_1_branch2b_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv2.norm.running_mean              loaded from res3_1_branch2b_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv2.norm.running_var               loaded from res3_1_branch2b_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv2.norm.weight                    loaded from res3_1_branch2b_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv2.weight                         loaded from res3_1_branch2b_w                 of shape (128, 128, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv3.norm.bias                      loaded from res3_1_branch2c_bn_beta           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv3.norm.running_mean              loaded from res3_1_branch2c_bn_running_mean   of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv3.norm.running_var               loaded from res3_1_branch2c_bn_running_var    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv3.norm.weight                    loaded from res3_1_branch2c_bn_gamma          of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.1.conv3.weight                         loaded from res3_1_branch2c_w                 of shape (512, 128, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv1.norm.bias                      loaded from res3_2_branch2a_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv1.norm.running_mean              loaded from res3_2_branch2a_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv1.norm.running_var               loaded from res3_2_branch2a_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv1.norm.weight                    loaded from res3_2_branch2a_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv1.weight                         loaded from res3_2_branch2a_w                 of shape (128, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv2.norm.bias                      loaded from res3_2_branch2b_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv2.norm.running_mean              loaded from res3_2_branch2b_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv2.norm.running_var               loaded from res3_2_branch2b_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv2.norm.weight                    loaded from res3_2_branch2b_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv2.weight                         loaded from res3_2_branch2b_w                 of shape (128, 128, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv3.norm.bias                      loaded from res3_2_branch2c_bn_beta           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv3.norm.running_mean              loaded from res3_2_branch2c_bn_running_mean   of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv3.norm.running_var               loaded from res3_2_branch2c_bn_running_var    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv3.norm.weight                    loaded from res3_2_branch2c_bn_gamma          of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.2.conv3.weight                         loaded from res3_2_branch2c_w                 of shape (512, 128, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv1.norm.bias                      loaded from res3_3_branch2a_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv1.norm.running_mean              loaded from res3_3_branch2a_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv1.norm.running_var               loaded from res3_3_branch2a_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv1.norm.weight                    loaded from res3_3_branch2a_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv1.weight                         loaded from res3_3_branch2a_w                 of shape (128, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv2.norm.bias                      loaded from res3_3_branch2b_bn_beta           of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv2.norm.running_mean              loaded from res3_3_branch2b_bn_running_mean   of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv2.norm.running_var               loaded from res3_3_branch2b_bn_running_var    of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv2.norm.weight                    loaded from res3_3_branch2b_bn_gamma          of shape (128,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv2.weight                         loaded from res3_3_branch2b_w                 of shape (128, 128, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv3.norm.bias                      loaded from res3_3_branch2c_bn_beta           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv3.norm.running_mean              loaded from res3_3_branch2c_bn_running_mean   of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv3.norm.running_var               loaded from res3_3_branch2c_bn_running_var    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv3.norm.weight                    loaded from res3_3_branch2c_bn_gamma          of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res3.3.conv3.weight                         loaded from res3_3_branch2c_w                 of shape (512, 128, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv1.norm.bias                      loaded from res4_0_branch2a_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv1.norm.running_mean              loaded from res4_0_branch2a_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv1.norm.running_var               loaded from res4_0_branch2a_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv1.norm.weight                    loaded from res4_0_branch2a_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv1.weight                         loaded from res4_0_branch2a_w                 of shape (256, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv2.norm.bias                      loaded from res4_0_branch2b_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv2.norm.running_mean              loaded from res4_0_branch2b_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv2.norm.running_var               loaded from res4_0_branch2b_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv2.norm.weight                    loaded from res4_0_branch2b_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv2.weight                         loaded from res4_0_branch2b_w                 of shape (256, 256, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv3.norm.bias                      loaded from res4_0_branch2c_bn_beta           of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv3.norm.running_mean              loaded from res4_0_branch2c_bn_running_mean   of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv3.norm.running_var               loaded from res4_0_branch2c_bn_running_var    of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv3.norm.weight                    loaded from res4_0_branch2c_bn_gamma          of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.conv3.weight                         loaded from res4_0_branch2c_w                 of shape (1024, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.shortcut.norm.bias                   loaded from res4_0_branch1_bn_beta            of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.shortcut.norm.running_mean           loaded from res4_0_branch1_bn_running_mean    of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.shortcut.norm.running_var            loaded from res4_0_branch1_bn_running_var     of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.shortcut.norm.weight                 loaded from res4_0_branch1_bn_gamma           of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.0.shortcut.weight                      loaded from res4_0_branch1_w                  of shape (1024, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv1.norm.bias                      loaded from res4_1_branch2a_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv1.norm.running_mean              loaded from res4_1_branch2a_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv1.norm.running_var               loaded from res4_1_branch2a_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv1.norm.weight                    loaded from res4_1_branch2a_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv1.weight                         loaded from res4_1_branch2a_w                 of shape (256, 1024, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv2.norm.bias                      loaded from res4_1_branch2b_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv2.norm.running_mean              loaded from res4_1_branch2b_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv2.norm.running_var               loaded from res4_1_branch2b_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv2.norm.weight                    loaded from res4_1_branch2b_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv2.weight                         loaded from res4_1_branch2b_w                 of shape (256, 256, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv3.norm.bias                      loaded from res4_1_branch2c_bn_beta           of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv3.norm.running_mean              loaded from res4_1_branch2c_bn_running_mean   of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv3.norm.running_var               loaded from res4_1_branch2c_bn_running_var    of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv3.norm.weight                    loaded from res4_1_branch2c_bn_gamma          of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.1.conv3.weight                         loaded from res4_1_branch2c_w                 of shape (1024, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv1.norm.bias                      loaded from res4_2_branch2a_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv1.norm.running_mean              loaded from res4_2_branch2a_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv1.norm.running_var               loaded from res4_2_branch2a_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv1.norm.weight                    loaded from res4_2_branch2a_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv1.weight                         loaded from res4_2_branch2a_w                 of shape (256, 1024, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv2.norm.bias                      loaded from res4_2_branch2b_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv2.norm.running_mean              loaded from res4_2_branch2b_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv2.norm.running_var               loaded from res4_2_branch2b_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv2.norm.weight                    loaded from res4_2_branch2b_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv2.weight                         loaded from res4_2_branch2b_w                 of shape (256, 256, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv3.norm.bias                      loaded from res4_2_branch2c_bn_beta           of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv3.norm.running_mean              loaded from res4_2_branch2c_bn_running_mean   of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv3.norm.running_var               loaded from res4_2_branch2c_bn_running_var    of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv3.norm.weight                    loaded from res4_2_branch2c_bn_gamma          of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.2.conv3.weight                         loaded from res4_2_branch2c_w                 of shape (1024, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv1.norm.bias                      loaded from res4_3_branch2a_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv1.norm.running_mean              loaded from res4_3_branch2a_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv1.norm.running_var               loaded from res4_3_branch2a_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv1.norm.weight                    loaded from res4_3_branch2a_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv1.weight                         loaded from res4_3_branch2a_w                 of shape (256, 1024, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv2.norm.bias                      loaded from res4_3_branch2b_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv2.norm.running_mean              loaded from res4_3_branch2b_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv2.norm.running_var               loaded from res4_3_branch2b_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv2.norm.weight                    loaded from res4_3_branch2b_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv2.weight                         loaded from res4_3_branch2b_w                 of shape (256, 256, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv3.norm.bias                      loaded from res4_3_branch2c_bn_beta           of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv3.norm.running_mean              loaded from res4_3_branch2c_bn_running_mean   of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv3.norm.running_var               loaded from res4_3_branch2c_bn_running_var    of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv3.norm.weight                    loaded from res4_3_branch2c_bn_gamma          of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.3.conv3.weight                         loaded from res4_3_branch2c_w                 of shape (1024, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv1.norm.bias                      loaded from res4_4_branch2a_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv1.norm.running_mean              loaded from res4_4_branch2a_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv1.norm.running_var               loaded from res4_4_branch2a_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv1.norm.weight                    loaded from res4_4_branch2a_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv1.weight                         loaded from res4_4_branch2a_w                 of shape (256, 1024, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv2.norm.bias                      loaded from res4_4_branch2b_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv2.norm.running_mean              loaded from res4_4_branch2b_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv2.norm.running_var               loaded from res4_4_branch2b_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv2.norm.weight                    loaded from res4_4_branch2b_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv2.weight                         loaded from res4_4_branch2b_w                 of shape (256, 256, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv3.norm.bias                      loaded from res4_4_branch2c_bn_beta           of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv3.norm.running_mean              loaded from res4_4_branch2c_bn_running_mean   of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv3.norm.running_var               loaded from res4_4_branch2c_bn_running_var    of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv3.norm.weight                    loaded from res4_4_branch2c_bn_gamma          of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.4.conv3.weight                         loaded from res4_4_branch2c_w                 of shape (1024, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv1.norm.bias                      loaded from res4_5_branch2a_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv1.norm.running_mean              loaded from res4_5_branch2a_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv1.norm.running_var               loaded from res4_5_branch2a_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv1.norm.weight                    loaded from res4_5_branch2a_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv1.weight                         loaded from res4_5_branch2a_w                 of shape (256, 1024, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv2.norm.bias                      loaded from res4_5_branch2b_bn_beta           of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv2.norm.running_mean              loaded from res4_5_branch2b_bn_running_mean   of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv2.norm.running_var               loaded from res4_5_branch2b_bn_running_var    of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv2.norm.weight                    loaded from res4_5_branch2b_bn_gamma          of shape (256,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv2.weight                         loaded from res4_5_branch2b_w                 of shape (256, 256, 3, 3)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv3.norm.bias                      loaded from res4_5_branch2c_bn_beta           of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv3.norm.running_mean              loaded from res4_5_branch2c_bn_running_mean   of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv3.norm.running_var               loaded from res4_5_branch2c_bn_running_var    of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv3.norm.weight                    loaded from res4_5_branch2c_bn_gamma          of shape (1024,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.res4.5.conv3.weight                         loaded from res4_5_branch2c_w                 of shape (1024, 256, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.stem.conv1.norm.bias                        loaded from res_conv1_bn_beta                 of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.stem.conv1.norm.running_mean                loaded from res_conv1_bn_running_mean         of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.stem.conv1.norm.running_var                 loaded from res_conv1_bn_running_var          of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.stem.conv1.norm.weight                      loaded from res_conv1_bn_gamma                of shape (64,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mbackbone.stem.conv1.weight                           loaded from conv1_w                           of shape (64, 3, 7, 7)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv1.norm.bias                     loaded from res5_0_branch2a_bn_beta           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv1.norm.running_mean             loaded from res5_0_branch2a_bn_running_mean   of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv1.norm.running_var              loaded from res5_0_branch2a_bn_running_var    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv1.norm.weight                   loaded from res5_0_branch2a_bn_gamma          of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv1.weight                        loaded from res5_0_branch2a_w                 of shape (512, 1024, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv3.norm.bias                     loaded from res5_0_branch2c_bn_beta           of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv3.norm.running_mean             loaded from res5_0_branch2c_bn_running_mean   of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv3.norm.running_var              loaded from res5_0_branch2c_bn_running_var    of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv3.norm.weight                   loaded from res5_0_branch2c_bn_gamma          of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.conv3.weight                        loaded from res5_0_branch2c_w                 of shape (2048, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.shortcut.norm.bias                  loaded from res5_0_branch1_bn_beta            of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.shortcut.norm.running_mean          loaded from res5_0_branch1_bn_running_mean    of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.shortcut.norm.running_var           loaded from res5_0_branch1_bn_running_var     of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.shortcut.norm.weight                loaded from res5_0_branch1_bn_gamma           of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.0.shortcut.weight                     loaded from res5_0_branch1_w                  of shape (2048, 1024, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv1.norm.bias                     loaded from res5_1_branch2a_bn_beta           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv1.norm.running_mean             loaded from res5_1_branch2a_bn_running_mean   of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv1.norm.running_var              loaded from res5_1_branch2a_bn_running_var    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv1.norm.weight                   loaded from res5_1_branch2a_bn_gamma          of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv1.weight                        loaded from res5_1_branch2a_w                 of shape (512, 2048, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv3.norm.bias                     loaded from res5_1_branch2c_bn_beta           of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv3.norm.running_mean             loaded from res5_1_branch2c_bn_running_mean   of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv3.norm.running_var              loaded from res5_1_branch2c_bn_running_var    of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv3.norm.weight                   loaded from res5_1_branch2c_bn_gamma          of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.1.conv3.weight                        loaded from res5_1_branch2c_w                 of shape (2048, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv1.norm.bias                     loaded from res5_2_branch2a_bn_beta           of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv1.norm.running_mean             loaded from res5_2_branch2a_bn_running_mean   of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv1.norm.running_var              loaded from res5_2_branch2a_bn_running_var    of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv1.norm.weight                   loaded from res5_2_branch2a_bn_gamma          of shape (512,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv1.weight                        loaded from res5_2_branch2a_w                 of shape (512, 2048, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv3.norm.bias                     loaded from res5_2_branch2c_bn_beta           of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv3.norm.running_mean             loaded from res5_2_branch2c_bn_running_mean   of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv3.norm.running_var              loaded from res5_2_branch2c_bn_running_var    of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv3.norm.weight                   loaded from res5_2_branch2c_bn_gamma          of shape (2048,)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:299]: \u001b[0mroi_heads.res5.2.conv3.weight                        loaded from res5_2_branch2c_w                 of shape (2048, 512, 1, 1)\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:307]: \u001b[0mSome model parameters are not in the checkpoint:\r\n",
      "  \u001b[34mproposal_generator.anchor_generator.cell_anchors.0\u001b[0m\r\n",
      "  \u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.0.conv2.bn0.{bias, running_mean, running_var, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.0.conv2.bn1.{bias, running_mean, running_var, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.0.conv2.conv.weight\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.0.conv2.fc1.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.0.conv2.fc2.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.1.conv2.bn0.{bias, running_mean, running_var, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.1.conv2.bn1.{bias, running_mean, running_var, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.1.conv2.conv.weight\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.1.conv2.fc1.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.1.conv2.fc2.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.2.conv2.bn0.{bias, running_mean, running_var, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.2.conv2.bn1.{bias, running_mean, running_var, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.2.conv2.conv.weight\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.2.conv2.fc1.{bias, weight}\u001b[0m\r\n",
      "  \u001b[34mroi_heads.res5.2.conv2.fc2.{bias, weight}\u001b[0m\r\n",
      "\u001b[32m[05/16 11:24:17 d2.checkpoint.c2_model_loading:312]: \u001b[0mThe checkpoint contains parameters not used by the model:\r\n",
      "  \u001b[35mfc1000_b\u001b[0m\r\n",
      "  \u001b[35mfc1000_w\u001b[0m\r\n",
      "  \u001b[35mres5_0_branch2b_bn_beta\u001b[0m\r\n",
      "  \u001b[35mres5_0_branch2b_bn_running_mean\u001b[0m\r\n",
      "  \u001b[35mres5_0_branch2b_bn_running_var\u001b[0m\r\n",
      "  \u001b[35mres5_0_branch2b_bn_gamma\u001b[0m\r\n",
      "  \u001b[35mres5_0_branch2b_w\u001b[0m\r\n",
      "  \u001b[35mres5_1_branch2b_bn_beta\u001b[0m\r\n",
      "  \u001b[35mres5_1_branch2b_bn_running_mean\u001b[0m\r\n",
      "  \u001b[35mres5_1_branch2b_bn_running_var\u001b[0m\r\n",
      "  \u001b[35mres5_1_branch2b_bn_gamma\u001b[0m\r\n",
      "  \u001b[35mres5_1_branch2b_w\u001b[0m\r\n",
      "  \u001b[35mres5_2_branch2b_bn_beta\u001b[0m\r\n",
      "  \u001b[35mres5_2_branch2b_bn_running_mean\u001b[0m\r\n",
      "  \u001b[35mres5_2_branch2b_bn_running_var\u001b[0m\r\n",
      "  \u001b[35mres5_2_branch2b_bn_gamma\u001b[0m\r\n",
      "  \u001b[35mres5_2_branch2b_w\u001b[0m\r\n",
      "  \u001b[35mconv1_b\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 11:24:17 d2.engine.train_loop:122]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[05/16 11:24:52 d2.utils.events:215]: \u001b[0m eta: 0:56:50  iter: 19  total_loss: 3.509  loss_cls: 2.433  loss_box_reg: 0.297  loss_rpn_cls: 0.684  loss_rpn_loc: 0.054  time: 1.7217  data_time: 0.0130  lr: 0.000191  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:25:26 d2.utils.events:215]: \u001b[0m eta: 0:56:28  iter: 39  total_loss: 2.139  loss_cls: 1.023  loss_box_reg: 0.289  loss_rpn_cls: 0.592  loss_rpn_loc: 0.075  time: 1.7275  data_time: 0.0059  lr: 0.000391  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:26:01 d2.utils.events:215]: \u001b[0m eta: 0:56:06  iter: 59  total_loss: 1.227  loss_cls: 0.449  loss_box_reg: 0.287  loss_rpn_cls: 0.390  loss_rpn_loc: 0.069  time: 1.7330  data_time: 0.0061  lr: 0.000590  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:26:36 d2.utils.events:215]: \u001b[0m eta: 0:55:39  iter: 79  total_loss: 1.096  loss_cls: 0.381  loss_box_reg: 0.408  loss_rpn_cls: 0.291  loss_rpn_loc: 0.085  time: 1.7368  data_time: 0.0061  lr: 0.000790  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:27:11 d2.utils.events:215]: \u001b[0m eta: 0:55:10  iter: 99  total_loss: 1.296  loss_cls: 0.497  loss_box_reg: 0.451  loss_rpn_cls: 0.192  loss_rpn_loc: 0.055  time: 1.7405  data_time: 0.0065  lr: 0.000990  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:27:46 d2.utils.events:215]: \u001b[0m eta: 0:54:41  iter: 119  total_loss: 1.335  loss_cls: 0.505  loss_box_reg: 0.617  loss_rpn_cls: 0.138  loss_rpn_loc: 0.059  time: 1.7437  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:28:22 d2.utils.events:215]: \u001b[0m eta: 0:54:14  iter: 139  total_loss: 1.132  loss_cls: 0.415  loss_box_reg: 0.493  loss_rpn_cls: 0.131  loss_rpn_loc: 0.046  time: 1.7487  data_time: 0.0061  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:28:57 d2.utils.events:215]: \u001b[0m eta: 0:53:45  iter: 159  total_loss: 1.470  loss_cls: 0.532  loss_box_reg: 0.720  loss_rpn_cls: 0.140  loss_rpn_loc: 0.056  time: 1.7513  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:29:33 d2.utils.events:215]: \u001b[0m eta: 0:53:12  iter: 179  total_loss: 1.701  loss_cls: 0.638  loss_box_reg: 0.714  loss_rpn_cls: 0.173  loss_rpn_loc: 0.083  time: 1.7530  data_time: 0.0065  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:30:08 d2.utils.events:215]: \u001b[0m eta: 0:52:41  iter: 199  total_loss: 1.563  loss_cls: 0.564  loss_box_reg: 0.776  loss_rpn_cls: 0.136  loss_rpn_loc: 0.090  time: 1.7547  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:30:44 d2.utils.events:215]: \u001b[0m eta: 0:52:13  iter: 219  total_loss: 1.315  loss_cls: 0.503  loss_box_reg: 0.616  loss_rpn_cls: 0.097  loss_rpn_loc: 0.073  time: 1.7562  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:31:19 d2.utils.events:215]: \u001b[0m eta: 0:51:39  iter: 239  total_loss: 1.327  loss_cls: 0.507  loss_box_reg: 0.641  loss_rpn_cls: 0.090  loss_rpn_loc: 0.056  time: 1.7569  data_time: 0.0065  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:31:54 d2.utils.events:215]: \u001b[0m eta: 0:51:06  iter: 259  total_loss: 1.302  loss_cls: 0.503  loss_box_reg: 0.617  loss_rpn_cls: 0.073  loss_rpn_loc: 0.048  time: 1.7577  data_time: 0.0065  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:32:29 d2.utils.events:215]: \u001b[0m eta: 0:50:31  iter: 279  total_loss: 1.257  loss_cls: 0.444  loss_box_reg: 0.623  loss_rpn_cls: 0.082  loss_rpn_loc: 0.057  time: 1.7579  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:33:05 d2.utils.events:215]: \u001b[0m eta: 0:49:54  iter: 299  total_loss: 1.432  loss_cls: 0.527  loss_box_reg: 0.671  loss_rpn_cls: 0.079  loss_rpn_loc: 0.050  time: 1.7578  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:33:40 d2.utils.events:215]: \u001b[0m eta: 0:49:19  iter: 319  total_loss: 1.341  loss_cls: 0.509  loss_box_reg: 0.611  loss_rpn_cls: 0.061  loss_rpn_loc: 0.051  time: 1.7580  data_time: 0.0064  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:34:15 d2.utils.events:215]: \u001b[0m eta: 0:48:44  iter: 339  total_loss: 1.319  loss_cls: 0.487  loss_box_reg: 0.634  loss_rpn_cls: 0.070  loss_rpn_loc: 0.067  time: 1.7581  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:34:50 d2.utils.events:215]: \u001b[0m eta: 0:48:10  iter: 359  total_loss: 1.476  loss_cls: 0.550  loss_box_reg: 0.695  loss_rpn_cls: 0.084  loss_rpn_loc: 0.054  time: 1.7586  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:35:26 d2.utils.events:215]: \u001b[0m eta: 0:47:35  iter: 379  total_loss: 1.210  loss_cls: 0.450  loss_box_reg: 0.657  loss_rpn_cls: 0.045  loss_rpn_loc: 0.039  time: 1.7589  data_time: 0.0064  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:36:01 d2.utils.events:215]: \u001b[0m eta: 0:46:59  iter: 399  total_loss: 1.311  loss_cls: 0.483  loss_box_reg: 0.697  loss_rpn_cls: 0.049  loss_rpn_loc: 0.039  time: 1.7590  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:36:36 d2.utils.events:215]: \u001b[0m eta: 0:46:24  iter: 419  total_loss: 1.430  loss_cls: 0.523  loss_box_reg: 0.767  loss_rpn_cls: 0.063  loss_rpn_loc: 0.057  time: 1.7591  data_time: 0.0064  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:37:12 d2.utils.events:215]: \u001b[0m eta: 0:45:49  iter: 439  total_loss: 1.357  loss_cls: 0.499  loss_box_reg: 0.655  loss_rpn_cls: 0.077  loss_rpn_loc: 0.071  time: 1.7594  data_time: 0.0068  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:37:47 d2.utils.events:215]: \u001b[0m eta: 0:45:14  iter: 459  total_loss: 1.517  loss_cls: 0.575  loss_box_reg: 0.795  loss_rpn_cls: 0.081  loss_rpn_loc: 0.056  time: 1.7597  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:38:22 d2.utils.events:215]: \u001b[0m eta: 0:44:39  iter: 479  total_loss: 1.212  loss_cls: 0.429  loss_box_reg: 0.684  loss_rpn_cls: 0.054  loss_rpn_loc: 0.036  time: 1.7598  data_time: 0.0066  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:38:57 d2.utils.events:215]: \u001b[0m eta: 0:44:04  iter: 499  total_loss: 1.120  loss_cls: 0.393  loss_box_reg: 0.595  loss_rpn_cls: 0.072  loss_rpn_loc: 0.045  time: 1.7599  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:39:33 d2.utils.events:215]: \u001b[0m eta: 0:43:29  iter: 519  total_loss: 1.260  loss_cls: 0.446  loss_box_reg: 0.656  loss_rpn_cls: 0.085  loss_rpn_loc: 0.072  time: 1.7602  data_time: 0.0065  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:40:08 d2.utils.events:215]: \u001b[0m eta: 0:42:54  iter: 539  total_loss: 1.404  loss_cls: 0.473  loss_box_reg: 0.795  loss_rpn_cls: 0.072  loss_rpn_loc: 0.055  time: 1.7602  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:40:43 d2.utils.events:215]: \u001b[0m eta: 0:42:19  iter: 559  total_loss: 1.298  loss_cls: 0.450  loss_box_reg: 0.714  loss_rpn_cls: 0.062  loss_rpn_loc: 0.049  time: 1.7603  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:41:19 d2.utils.events:215]: \u001b[0m eta: 0:41:44  iter: 579  total_loss: 1.503  loss_cls: 0.524  loss_box_reg: 0.769  loss_rpn_cls: 0.071  loss_rpn_loc: 0.045  time: 1.7603  data_time: 0.0064  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:41:54 d2.utils.events:215]: \u001b[0m eta: 0:41:08  iter: 599  total_loss: 1.408  loss_cls: 0.447  loss_box_reg: 0.791  loss_rpn_cls: 0.071  loss_rpn_loc: 0.063  time: 1.7603  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:42:29 d2.utils.events:215]: \u001b[0m eta: 0:40:33  iter: 619  total_loss: 1.293  loss_cls: 0.418  loss_box_reg: 0.732  loss_rpn_cls: 0.066  loss_rpn_loc: 0.058  time: 1.7603  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:43:04 d2.utils.events:215]: \u001b[0m eta: 0:39:58  iter: 639  total_loss: 1.262  loss_cls: 0.408  loss_box_reg: 0.699  loss_rpn_cls: 0.059  loss_rpn_loc: 0.052  time: 1.7605  data_time: 0.0064  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:43:40 d2.utils.events:215]: \u001b[0m eta: 0:39:23  iter: 659  total_loss: 1.258  loss_cls: 0.416  loss_box_reg: 0.708  loss_rpn_cls: 0.070  loss_rpn_loc: 0.034  time: 1.7606  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:44:15 d2.utils.events:215]: \u001b[0m eta: 0:38:47  iter: 679  total_loss: 1.217  loss_cls: 0.419  loss_box_reg: 0.704  loss_rpn_cls: 0.054  loss_rpn_loc: 0.054  time: 1.7604  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:44:50 d2.utils.events:215]: \u001b[0m eta: 0:38:12  iter: 699  total_loss: 1.307  loss_cls: 0.430  loss_box_reg: 0.683  loss_rpn_cls: 0.069  loss_rpn_loc: 0.068  time: 1.7606  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 11:45:26 d2.utils.events:215]: \u001b[0m eta: 0:37:37  iter: 719  total_loss: 1.110  loss_cls: 0.362  loss_box_reg: 0.573  loss_rpn_cls: 0.065  loss_rpn_loc: 0.059  time: 1.7608  data_time: 0.0058  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:46:01 d2.utils.events:215]: \u001b[0m eta: 0:37:02  iter: 739  total_loss: 1.204  loss_cls: 0.366  loss_box_reg: 0.716  loss_rpn_cls: 0.079  loss_rpn_loc: 0.048  time: 1.7610  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:46:36 d2.utils.events:215]: \u001b[0m eta: 0:36:27  iter: 759  total_loss: 1.210  loss_cls: 0.402  loss_box_reg: 0.664  loss_rpn_cls: 0.056  loss_rpn_loc: 0.036  time: 1.7610  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:47:11 d2.utils.events:215]: \u001b[0m eta: 0:35:52  iter: 779  total_loss: 1.203  loss_cls: 0.425  loss_box_reg: 0.648  loss_rpn_cls: 0.064  loss_rpn_loc: 0.049  time: 1.7611  data_time: 0.0058  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:47:47 d2.utils.events:215]: \u001b[0m eta: 0:35:17  iter: 799  total_loss: 1.215  loss_cls: 0.386  loss_box_reg: 0.717  loss_rpn_cls: 0.057  loss_rpn_loc: 0.043  time: 1.7611  data_time: 0.0057  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:48:22 d2.utils.events:215]: \u001b[0m eta: 0:34:41  iter: 819  total_loss: 1.296  loss_cls: 0.455  loss_box_reg: 0.740  loss_rpn_cls: 0.060  loss_rpn_loc: 0.056  time: 1.7610  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:48:57 d2.utils.events:215]: \u001b[0m eta: 0:34:06  iter: 839  total_loss: 1.054  loss_cls: 0.287  loss_box_reg: 0.620  loss_rpn_cls: 0.055  loss_rpn_loc: 0.037  time: 1.7610  data_time: 0.0061  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:49:32 d2.utils.events:215]: \u001b[0m eta: 0:33:30  iter: 859  total_loss: 1.107  loss_cls: 0.351  loss_box_reg: 0.694  loss_rpn_cls: 0.049  loss_rpn_loc: 0.039  time: 1.7609  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:50:08 d2.utils.events:215]: \u001b[0m eta: 0:32:55  iter: 879  total_loss: 0.989  loss_cls: 0.293  loss_box_reg: 0.604  loss_rpn_cls: 0.051  loss_rpn_loc: 0.037  time: 1.7610  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:50:43 d2.utils.events:215]: \u001b[0m eta: 0:32:20  iter: 899  total_loss: 1.226  loss_cls: 0.400  loss_box_reg: 0.711  loss_rpn_cls: 0.052  loss_rpn_loc: 0.047  time: 1.7611  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:51:18 d2.utils.events:215]: \u001b[0m eta: 0:31:45  iter: 919  total_loss: 1.104  loss_cls: 0.333  loss_box_reg: 0.627  loss_rpn_cls: 0.066  loss_rpn_loc: 0.054  time: 1.7611  data_time: 0.0058  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:51:53 d2.utils.events:215]: \u001b[0m eta: 0:31:09  iter: 939  total_loss: 1.140  loss_cls: 0.360  loss_box_reg: 0.632  loss_rpn_cls: 0.043  loss_rpn_loc: 0.037  time: 1.7611  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:52:29 d2.utils.events:215]: \u001b[0m eta: 0:30:34  iter: 959  total_loss: 1.115  loss_cls: 0.371  loss_box_reg: 0.649  loss_rpn_cls: 0.071  loss_rpn_loc: 0.039  time: 1.7611  data_time: 0.0056  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:53:04 d2.utils.events:215]: \u001b[0m eta: 0:29:59  iter: 979  total_loss: 1.175  loss_cls: 0.432  loss_box_reg: 0.659  loss_rpn_cls: 0.051  loss_rpn_loc: 0.039  time: 1.7611  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:53:39 d2.utils.events:215]: \u001b[0m eta: 0:29:24  iter: 999  total_loss: 1.171  loss_cls: 0.341  loss_box_reg: 0.638  loss_rpn_cls: 0.053  loss_rpn_loc: 0.032  time: 1.7611  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:54:14 d2.utils.events:215]: \u001b[0m eta: 0:28:49  iter: 1019  total_loss: 1.199  loss_cls: 0.430  loss_box_reg: 0.663  loss_rpn_cls: 0.054  loss_rpn_loc: 0.054  time: 1.7611  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:54:50 d2.utils.events:215]: \u001b[0m eta: 0:28:14  iter: 1039  total_loss: 1.152  loss_cls: 0.382  loss_box_reg: 0.652  loss_rpn_cls: 0.053  loss_rpn_loc: 0.049  time: 1.7612  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:55:25 d2.utils.events:215]: \u001b[0m eta: 0:27:39  iter: 1059  total_loss: 0.913  loss_cls: 0.317  loss_box_reg: 0.587  loss_rpn_cls: 0.040  loss_rpn_loc: 0.024  time: 1.7613  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:56:00 d2.utils.events:215]: \u001b[0m eta: 0:27:04  iter: 1079  total_loss: 1.144  loss_cls: 0.414  loss_box_reg: 0.651  loss_rpn_cls: 0.047  loss_rpn_loc: 0.050  time: 1.7613  data_time: 0.0055  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:56:36 d2.utils.events:215]: \u001b[0m eta: 0:26:29  iter: 1099  total_loss: 1.088  loss_cls: 0.348  loss_box_reg: 0.673  loss_rpn_cls: 0.066  loss_rpn_loc: 0.047  time: 1.7614  data_time: 0.0061  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:57:11 d2.utils.events:215]: \u001b[0m eta: 0:25:53  iter: 1119  total_loss: 1.156  loss_cls: 0.402  loss_box_reg: 0.688  loss_rpn_cls: 0.061  loss_rpn_loc: 0.053  time: 1.7615  data_time: 0.0056  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:57:46 d2.utils.events:215]: \u001b[0m eta: 0:25:18  iter: 1139  total_loss: 0.965  loss_cls: 0.298  loss_box_reg: 0.606  loss_rpn_cls: 0.037  loss_rpn_loc: 0.030  time: 1.7615  data_time: 0.0051  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:58:22 d2.utils.events:215]: \u001b[0m eta: 0:24:43  iter: 1159  total_loss: 1.034  loss_cls: 0.334  loss_box_reg: 0.601  loss_rpn_cls: 0.047  loss_rpn_loc: 0.040  time: 1.7615  data_time: 0.0040  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:58:57 d2.utils.events:215]: \u001b[0m eta: 0:24:07  iter: 1179  total_loss: 1.127  loss_cls: 0.367  loss_box_reg: 0.652  loss_rpn_cls: 0.040  loss_rpn_loc: 0.035  time: 1.7615  data_time: 0.0042  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 11:59:32 d2.utils.events:215]: \u001b[0m eta: 0:23:32  iter: 1199  total_loss: 1.100  loss_cls: 0.379  loss_box_reg: 0.620  loss_rpn_cls: 0.054  loss_rpn_loc: 0.042  time: 1.7615  data_time: 0.0058  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:00:07 d2.utils.events:215]: \u001b[0m eta: 0:22:56  iter: 1219  total_loss: 1.227  loss_cls: 0.378  loss_box_reg: 0.672  loss_rpn_cls: 0.061  loss_rpn_loc: 0.041  time: 1.7615  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:00:43 d2.utils.events:215]: \u001b[0m eta: 0:22:21  iter: 1239  total_loss: 1.241  loss_cls: 0.377  loss_box_reg: 0.682  loss_rpn_cls: 0.056  loss_rpn_loc: 0.040  time: 1.7617  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:01:18 d2.utils.events:215]: \u001b[0m eta: 0:21:46  iter: 1259  total_loss: 1.171  loss_cls: 0.370  loss_box_reg: 0.664  loss_rpn_cls: 0.049  loss_rpn_loc: 0.048  time: 1.7618  data_time: 0.0057  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:01:54 d2.utils.events:215]: \u001b[0m eta: 0:21:11  iter: 1279  total_loss: 0.982  loss_cls: 0.318  loss_box_reg: 0.541  loss_rpn_cls: 0.040  loss_rpn_loc: 0.028  time: 1.7619  data_time: 0.0061  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:02:29 d2.utils.events:215]: \u001b[0m eta: 0:20:36  iter: 1299  total_loss: 1.010  loss_cls: 0.311  loss_box_reg: 0.608  loss_rpn_cls: 0.040  loss_rpn_loc: 0.038  time: 1.7619  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:03:04 d2.utils.events:215]: \u001b[0m eta: 0:20:00  iter: 1319  total_loss: 1.266  loss_cls: 0.398  loss_box_reg: 0.686  loss_rpn_cls: 0.069  loss_rpn_loc: 0.061  time: 1.7619  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:03:39 d2.utils.events:215]: \u001b[0m eta: 0:19:25  iter: 1339  total_loss: 1.091  loss_cls: 0.356  loss_box_reg: 0.624  loss_rpn_cls: 0.043  loss_rpn_loc: 0.027  time: 1.7619  data_time: 0.0061  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:04:15 d2.utils.events:215]: \u001b[0m eta: 0:18:50  iter: 1359  total_loss: 1.047  loss_cls: 0.335  loss_box_reg: 0.629  loss_rpn_cls: 0.043  loss_rpn_loc: 0.041  time: 1.7620  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:04:50 d2.utils.events:215]: \u001b[0m eta: 0:18:15  iter: 1379  total_loss: 0.962  loss_cls: 0.268  loss_box_reg: 0.596  loss_rpn_cls: 0.033  loss_rpn_loc: 0.030  time: 1.7620  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:05:25 d2.utils.events:215]: \u001b[0m eta: 0:17:39  iter: 1399  total_loss: 1.059  loss_cls: 0.322  loss_box_reg: 0.631  loss_rpn_cls: 0.046  loss_rpn_loc: 0.045  time: 1.7621  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 12:06:01 d2.utils.events:215]: \u001b[0m eta: 0:17:04  iter: 1419  total_loss: 1.099  loss_cls: 0.359  loss_box_reg: 0.619  loss_rpn_cls: 0.050  loss_rpn_loc: 0.051  time: 1.7622  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:06:36 d2.utils.events:215]: \u001b[0m eta: 0:16:29  iter: 1439  total_loss: 1.097  loss_cls: 0.339  loss_box_reg: 0.654  loss_rpn_cls: 0.050  loss_rpn_loc: 0.049  time: 1.7621  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:07:11 d2.utils.events:215]: \u001b[0m eta: 0:15:54  iter: 1459  total_loss: 1.126  loss_cls: 0.337  loss_box_reg: 0.690  loss_rpn_cls: 0.064  loss_rpn_loc: 0.062  time: 1.7621  data_time: 0.0056  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:07:47 d2.utils.events:215]: \u001b[0m eta: 0:15:18  iter: 1479  total_loss: 1.016  loss_cls: 0.327  loss_box_reg: 0.585  loss_rpn_cls: 0.039  loss_rpn_loc: 0.028  time: 1.7622  data_time: 0.0056  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:08:22 d2.utils.events:215]: \u001b[0m eta: 0:14:43  iter: 1499  total_loss: 1.065  loss_cls: 0.340  loss_box_reg: 0.681  loss_rpn_cls: 0.052  loss_rpn_loc: 0.037  time: 1.7622  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:08:57 d2.utils.events:215]: \u001b[0m eta: 0:14:08  iter: 1519  total_loss: 1.175  loss_cls: 0.343  loss_box_reg: 0.630  loss_rpn_cls: 0.049  loss_rpn_loc: 0.041  time: 1.7623  data_time: 0.0055  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:09:32 d2.utils.events:215]: \u001b[0m eta: 0:13:33  iter: 1539  total_loss: 1.136  loss_cls: 0.342  loss_box_reg: 0.684  loss_rpn_cls: 0.055  loss_rpn_loc: 0.048  time: 1.7623  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:10:08 d2.utils.events:215]: \u001b[0m eta: 0:12:57  iter: 1559  total_loss: 0.815  loss_cls: 0.247  loss_box_reg: 0.499  loss_rpn_cls: 0.027  loss_rpn_loc: 0.035  time: 1.7624  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:10:43 d2.utils.events:215]: \u001b[0m eta: 0:12:22  iter: 1579  total_loss: 1.089  loss_cls: 0.362  loss_box_reg: 0.627  loss_rpn_cls: 0.043  loss_rpn_loc: 0.042  time: 1.7623  data_time: 0.0057  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:11:18 d2.utils.events:215]: \u001b[0m eta: 0:11:47  iter: 1599  total_loss: 1.117  loss_cls: 0.336  loss_box_reg: 0.647  loss_rpn_cls: 0.048  loss_rpn_loc: 0.050  time: 1.7623  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:11:54 d2.utils.events:215]: \u001b[0m eta: 0:11:12  iter: 1619  total_loss: 1.067  loss_cls: 0.355  loss_box_reg: 0.642  loss_rpn_cls: 0.051  loss_rpn_loc: 0.040  time: 1.7623  data_time: 0.0059  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:12:29 d2.utils.events:215]: \u001b[0m eta: 0:10:36  iter: 1639  total_loss: 0.939  loss_cls: 0.299  loss_box_reg: 0.569  loss_rpn_cls: 0.041  loss_rpn_loc: 0.028  time: 1.7624  data_time: 0.0058  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:13:04 d2.utils.events:215]: \u001b[0m eta: 0:10:01  iter: 1659  total_loss: 1.138  loss_cls: 0.346  loss_box_reg: 0.659  loss_rpn_cls: 0.045  loss_rpn_loc: 0.040  time: 1.7624  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:13:40 d2.utils.events:215]: \u001b[0m eta: 0:09:26  iter: 1679  total_loss: 0.977  loss_cls: 0.283  loss_box_reg: 0.631  loss_rpn_cls: 0.048  loss_rpn_loc: 0.041  time: 1.7624  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:14:15 d2.utils.events:215]: \u001b[0m eta: 0:08:50  iter: 1699  total_loss: 0.984  loss_cls: 0.295  loss_box_reg: 0.602  loss_rpn_cls: 0.037  loss_rpn_loc: 0.034  time: 1.7624  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:14:50 d2.utils.events:215]: \u001b[0m eta: 0:08:15  iter: 1719  total_loss: 0.927  loss_cls: 0.307  loss_box_reg: 0.603  loss_rpn_cls: 0.056  loss_rpn_loc: 0.038  time: 1.7624  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:15:25 d2.utils.events:215]: \u001b[0m eta: 0:07:40  iter: 1739  total_loss: 1.030  loss_cls: 0.294  loss_box_reg: 0.593  loss_rpn_cls: 0.051  loss_rpn_loc: 0.046  time: 1.7624  data_time: 0.0065  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:16:01 d2.utils.events:215]: \u001b[0m eta: 0:07:05  iter: 1759  total_loss: 0.977  loss_cls: 0.311  loss_box_reg: 0.615  loss_rpn_cls: 0.046  loss_rpn_loc: 0.035  time: 1.7625  data_time: 0.0065  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:16:36 d2.utils.events:215]: \u001b[0m eta: 0:06:29  iter: 1779  total_loss: 1.180  loss_cls: 0.336  loss_box_reg: 0.630  loss_rpn_cls: 0.060  loss_rpn_loc: 0.045  time: 1.7625  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:17:11 d2.utils.events:215]: \u001b[0m eta: 0:05:54  iter: 1799  total_loss: 1.101  loss_cls: 0.324  loss_box_reg: 0.639  loss_rpn_cls: 0.050  loss_rpn_loc: 0.039  time: 1.7625  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:17:47 d2.utils.events:215]: \u001b[0m eta: 0:05:19  iter: 1819  total_loss: 0.967  loss_cls: 0.308  loss_box_reg: 0.611  loss_rpn_cls: 0.038  loss_rpn_loc: 0.033  time: 1.7625  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:18:22 d2.utils.events:215]: \u001b[0m eta: 0:04:44  iter: 1839  total_loss: 0.800  loss_cls: 0.245  loss_box_reg: 0.520  loss_rpn_cls: 0.033  loss_rpn_loc: 0.021  time: 1.7625  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:18:57 d2.utils.events:215]: \u001b[0m eta: 0:04:08  iter: 1859  total_loss: 1.023  loss_cls: 0.287  loss_box_reg: 0.644  loss_rpn_cls: 0.041  loss_rpn_loc: 0.040  time: 1.7626  data_time: 0.0060  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:19:33 d2.utils.events:215]: \u001b[0m eta: 0:03:33  iter: 1879  total_loss: 1.059  loss_cls: 0.341  loss_box_reg: 0.651  loss_rpn_cls: 0.045  loss_rpn_loc: 0.042  time: 1.7626  data_time: 0.0066  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:20:08 d2.utils.events:215]: \u001b[0m eta: 0:02:58  iter: 1899  total_loss: 0.906  loss_cls: 0.265  loss_box_reg: 0.616  loss_rpn_cls: 0.030  loss_rpn_loc: 0.031  time: 1.7626  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:20:43 d2.utils.events:215]: \u001b[0m eta: 0:02:22  iter: 1919  total_loss: 1.004  loss_cls: 0.325  loss_box_reg: 0.637  loss_rpn_cls: 0.042  loss_rpn_loc: 0.035  time: 1.7627  data_time: 0.0063  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:21:19 d2.utils.events:215]: \u001b[0m eta: 0:01:47  iter: 1939  total_loss: 0.943  loss_cls: 0.285  loss_box_reg: 0.590  loss_rpn_cls: 0.042  loss_rpn_loc: 0.028  time: 1.7627  data_time: 0.0061  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:21:54 d2.utils.events:215]: \u001b[0m eta: 0:01:12  iter: 1959  total_loss: 0.968  loss_cls: 0.315  loss_box_reg: 0.570  loss_rpn_cls: 0.044  loss_rpn_loc: 0.039  time: 1.7627  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:22:29 d2.utils.events:215]: \u001b[0m eta: 0:00:37  iter: 1979  total_loss: 0.915  loss_cls: 0.276  loss_box_reg: 0.604  loss_rpn_cls: 0.043  loss_rpn_loc: 0.042  time: 1.7627  data_time: 0.0062  lr: 0.001000  max_mem: 1904M\n",
      "\u001b[32m[05/16 12:23:04 fvcore.common.checkpoint:73]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[05/16 12:23:06 d2.data.build:164]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|      car      | 8120         |    van     | 506          |   truck    | 129          |\n",
      "|  pedestrian   | 0            |   person   | 2010         |  cyclist   | 584          |\n",
      "|     tram      | 0            |    misc    | 96           |  dontcare  | 2921         |\n",
      "| person_sitt.. | 0            |            |              |            |              |\n",
      "|     total     | 14366        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[05/16 12:23:06 d2.data.common:88]: \u001b[0mSerializing 2065 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/16 12:23:06 d2.data.common:95]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
      "\u001b[32m[05/16 12:23:06 d2.evaluation.evaluator:123]: \u001b[0mStart inference on 2065 images\n",
      "\u001b[32m[05/16 12:23:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 11/2065. 2.0501 s / img. ETA=1:10:14\n",
      "\u001b[32m[05/16 12:23:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 14/2065. 2.0489 s / img. ETA=1:10:06\n",
      "\u001b[32m[05/16 12:23:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 17/2065. 2.0486 s / img. ETA=1:09:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 12:23:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 20/2065. 2.0488 s / img. ETA=1:09:54\n",
      "\u001b[32m[05/16 12:23:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 23/2065. 2.0480 s / img. ETA=1:09:46\n",
      "\u001b[32m[05/16 12:23:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 26/2065. 2.0481 s / img. ETA=1:09:40\n",
      "\u001b[32m[05/16 12:24:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 29/2065. 2.0474 s / img. ETA=1:09:32\n",
      "\u001b[32m[05/16 12:24:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 32/2065. 2.0474 s / img. ETA=1:09:26\n",
      "\u001b[32m[05/16 12:24:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 35/2065. 2.0468 s / img. ETA=1:09:19\n",
      "\u001b[32m[05/16 12:24:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 38/2065. 2.0474 s / img. ETA=1:09:14\n",
      "\u001b[32m[05/16 12:24:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 41/2065. 2.0471 s / img. ETA=1:09:07\n",
      "\u001b[32m[05/16 12:24:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 44/2065. 2.0470 s / img. ETA=1:09:01\n",
      "\u001b[32m[05/16 12:24:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 47/2065. 2.0469 s / img. ETA=1:08:55\n",
      "\u001b[32m[05/16 12:24:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 50/2065. 2.0469 s / img. ETA=1:08:48\n",
      "\u001b[32m[05/16 12:24:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 53/2065. 2.0467 s / img. ETA=1:08:42\n",
      "\u001b[32m[05/16 12:25:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 56/2065. 2.0466 s / img. ETA=1:08:36\n",
      "\u001b[32m[05/16 12:25:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 59/2065. 2.0467 s / img. ETA=1:08:30\n",
      "\u001b[32m[05/16 12:25:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 62/2065. 2.0467 s / img. ETA=1:08:24\n",
      "\u001b[32m[05/16 12:25:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 65/2065. 2.0468 s / img. ETA=1:08:17\n",
      "\u001b[32m[05/16 12:25:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 68/2065. 2.0468 s / img. ETA=1:08:11\n",
      "\u001b[32m[05/16 12:25:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 71/2065. 2.0467 s / img. ETA=1:08:05\n",
      "\u001b[32m[05/16 12:25:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 74/2065. 2.0466 s / img. ETA=1:07:59\n",
      "\u001b[32m[05/16 12:25:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 77/2065. 2.0466 s / img. ETA=1:07:53\n",
      "\u001b[32m[05/16 12:25:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 80/2065. 2.0466 s / img. ETA=1:07:46\n",
      "\u001b[32m[05/16 12:25:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 83/2065. 2.0466 s / img. ETA=1:07:40\n",
      "\u001b[32m[05/16 12:26:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 86/2065. 2.0465 s / img. ETA=1:07:34\n",
      "\u001b[32m[05/16 12:26:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 89/2065. 2.0467 s / img. ETA=1:07:28\n",
      "\u001b[32m[05/16 12:26:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 92/2065. 2.0468 s / img. ETA=1:07:22\n",
      "\u001b[32m[05/16 12:26:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 95/2065. 2.0469 s / img. ETA=1:07:16\n",
      "\u001b[32m[05/16 12:26:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 98/2065. 2.0469 s / img. ETA=1:07:10\n",
      "\u001b[32m[05/16 12:26:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 101/2065. 2.0469 s / img. ETA=1:07:04\n",
      "\u001b[32m[05/16 12:26:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 104/2065. 2.0468 s / img. ETA=1:06:58\n",
      "\u001b[32m[05/16 12:26:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 107/2065. 2.0469 s / img. ETA=1:06:52\n",
      "\u001b[32m[05/16 12:26:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 110/2065. 2.0469 s / img. ETA=1:06:45\n",
      "\u001b[32m[05/16 12:26:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 113/2065. 2.0468 s / img. ETA=1:06:39\n",
      "\u001b[32m[05/16 12:27:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 116/2065. 2.0470 s / img. ETA=1:06:33\n",
      "\u001b[32m[05/16 12:27:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 119/2065. 2.0471 s / img. ETA=1:06:28\n",
      "\u001b[32m[05/16 12:27:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 122/2065. 2.0470 s / img. ETA=1:06:21\n",
      "\u001b[32m[05/16 12:27:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 125/2065. 2.0470 s / img. ETA=1:06:15\n",
      "\u001b[32m[05/16 12:27:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 128/2065. 2.0470 s / img. ETA=1:06:09\n",
      "\u001b[32m[05/16 12:27:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 131/2065. 2.0470 s / img. ETA=1:06:03\n",
      "\u001b[32m[05/16 12:27:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 134/2065. 2.0471 s / img. ETA=1:05:57\n",
      "\u001b[32m[05/16 12:27:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 137/2065. 2.0471 s / img. ETA=1:05:51\n",
      "\u001b[32m[05/16 12:27:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 140/2065. 2.0472 s / img. ETA=1:05:45\n",
      "\u001b[32m[05/16 12:27:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 143/2065. 2.0472 s / img. ETA=1:05:39\n",
      "\u001b[32m[05/16 12:28:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 146/2065. 2.0472 s / img. ETA=1:05:33\n",
      "\u001b[32m[05/16 12:28:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 149/2065. 2.0471 s / img. ETA=1:05:26\n",
      "\u001b[32m[05/16 12:28:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 152/2065. 2.0472 s / img. ETA=1:05:20\n",
      "\u001b[32m[05/16 12:28:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 155/2065. 2.0472 s / img. ETA=1:05:14\n",
      "\u001b[32m[05/16 12:28:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 158/2065. 2.0472 s / img. ETA=1:05:08\n",
      "\u001b[32m[05/16 12:28:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 161/2065. 2.0473 s / img. ETA=1:05:02\n",
      "\u001b[32m[05/16 12:28:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 164/2065. 2.0472 s / img. ETA=1:04:56\n",
      "\u001b[32m[05/16 12:28:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 167/2065. 2.0472 s / img. ETA=1:04:49\n",
      "\u001b[32m[05/16 12:28:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 170/2065. 2.0472 s / img. ETA=1:04:43\n",
      "\u001b[32m[05/16 12:29:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 173/2065. 2.0472 s / img. ETA=1:04:37\n",
      "\u001b[32m[05/16 12:29:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 176/2065. 2.0472 s / img. ETA=1:04:31\n",
      "\u001b[32m[05/16 12:29:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 179/2065. 2.0472 s / img. ETA=1:04:25\n",
      "\u001b[32m[05/16 12:29:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 182/2065. 2.0473 s / img. ETA=1:04:19\n",
      "\u001b[32m[05/16 12:29:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 185/2065. 2.0472 s / img. ETA=1:04:13\n",
      "\u001b[32m[05/16 12:29:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 188/2065. 2.0472 s / img. ETA=1:04:06\n",
      "\u001b[32m[05/16 12:29:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 191/2065. 2.0472 s / img. ETA=1:04:00\n",
      "\u001b[32m[05/16 12:29:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 194/2065. 2.0473 s / img. ETA=1:03:54\n",
      "\u001b[32m[05/16 12:29:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 197/2065. 2.0472 s / img. ETA=1:03:48\n",
      "\u001b[32m[05/16 12:29:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 200/2065. 2.0472 s / img. ETA=1:03:42\n",
      "\u001b[32m[05/16 12:30:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 203/2065. 2.0472 s / img. ETA=1:03:36\n",
      "\u001b[32m[05/16 12:30:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 206/2065. 2.0472 s / img. ETA=1:03:29\n",
      "\u001b[32m[05/16 12:30:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 209/2065. 2.0473 s / img. ETA=1:03:23\n",
      "\u001b[32m[05/16 12:30:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 212/2065. 2.0473 s / img. ETA=1:03:17\n",
      "\u001b[32m[05/16 12:30:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 215/2065. 2.0473 s / img. ETA=1:03:11\n",
      "\u001b[32m[05/16 12:30:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 218/2065. 2.0472 s / img. ETA=1:03:05\n",
      "\u001b[32m[05/16 12:30:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 221/2065. 2.0472 s / img. ETA=1:02:59\n",
      "\u001b[32m[05/16 12:30:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 224/2065. 2.0472 s / img. ETA=1:02:53\n",
      "\u001b[32m[05/16 12:30:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 227/2065. 2.0472 s / img. ETA=1:02:46\n",
      "\u001b[32m[05/16 12:30:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 230/2065. 2.0472 s / img. ETA=1:02:40\n",
      "\u001b[32m[05/16 12:31:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 233/2065. 2.0472 s / img. ETA=1:02:34\n",
      "\u001b[32m[05/16 12:31:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 236/2065. 2.0471 s / img. ETA=1:02:28\n",
      "\u001b[32m[05/16 12:31:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 239/2065. 2.0471 s / img. ETA=1:02:22\n",
      "\u001b[32m[05/16 12:31:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 242/2065. 2.0471 s / img. ETA=1:02:16\n",
      "\u001b[32m[05/16 12:31:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 245/2065. 2.0472 s / img. ETA=1:02:09\n",
      "\u001b[32m[05/16 12:31:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 248/2065. 2.0471 s / img. ETA=1:02:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 12:31:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 251/2065. 2.0472 s / img. ETA=1:01:57\n",
      "\u001b[32m[05/16 12:31:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 254/2065. 2.0472 s / img. ETA=1:01:51\n",
      "\u001b[32m[05/16 12:31:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 257/2065. 2.0471 s / img. ETA=1:01:45\n",
      "\u001b[32m[05/16 12:31:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 260/2065. 2.0471 s / img. ETA=1:01:39\n",
      "\u001b[32m[05/16 12:32:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 263/2065. 2.0472 s / img. ETA=1:01:33\n",
      "\u001b[32m[05/16 12:32:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 266/2065. 2.0472 s / img. ETA=1:01:27\n",
      "\u001b[32m[05/16 12:32:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 269/2065. 2.0472 s / img. ETA=1:01:20\n",
      "\u001b[32m[05/16 12:32:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 272/2065. 2.0472 s / img. ETA=1:01:14\n",
      "\u001b[32m[05/16 12:32:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 275/2065. 2.0472 s / img. ETA=1:01:08\n",
      "\u001b[32m[05/16 12:32:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 278/2065. 2.0472 s / img. ETA=1:01:02\n",
      "\u001b[32m[05/16 12:32:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 281/2065. 2.0472 s / img. ETA=1:00:56\n",
      "\u001b[32m[05/16 12:32:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 284/2065. 2.0472 s / img. ETA=1:00:50\n",
      "\u001b[32m[05/16 12:32:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 287/2065. 2.0472 s / img. ETA=1:00:44\n",
      "\u001b[32m[05/16 12:33:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 290/2065. 2.0472 s / img. ETA=1:00:37\n",
      "\u001b[32m[05/16 12:33:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 293/2065. 2.0472 s / img. ETA=1:00:31\n",
      "\u001b[32m[05/16 12:33:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 296/2065. 2.0473 s / img. ETA=1:00:25\n",
      "\u001b[32m[05/16 12:33:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 299/2065. 2.0472 s / img. ETA=1:00:19\n",
      "\u001b[32m[05/16 12:33:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 302/2065. 2.0472 s / img. ETA=1:00:13\n",
      "\u001b[32m[05/16 12:33:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 305/2065. 2.0472 s / img. ETA=1:00:07\n",
      "\u001b[32m[05/16 12:33:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 308/2065. 2.0472 s / img. ETA=1:00:00\n",
      "\u001b[32m[05/16 12:33:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 311/2065. 2.0472 s / img. ETA=0:59:54\n",
      "\u001b[32m[05/16 12:33:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 314/2065. 2.0472 s / img. ETA=0:59:48\n",
      "\u001b[32m[05/16 12:33:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 317/2065. 2.0472 s / img. ETA=0:59:42\n",
      "\u001b[32m[05/16 12:34:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 320/2065. 2.0473 s / img. ETA=0:59:36\n",
      "\u001b[32m[05/16 12:34:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 323/2065. 2.0473 s / img. ETA=0:59:30\n",
      "\u001b[32m[05/16 12:34:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 326/2065. 2.0473 s / img. ETA=0:59:24\n",
      "\u001b[32m[05/16 12:34:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 329/2065. 2.0473 s / img. ETA=0:59:18\n",
      "\u001b[32m[05/16 12:34:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 332/2065. 2.0473 s / img. ETA=0:59:11\n",
      "\u001b[32m[05/16 12:34:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 335/2065. 2.0473 s / img. ETA=0:59:05\n",
      "\u001b[32m[05/16 12:34:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 338/2065. 2.0473 s / img. ETA=0:58:59\n",
      "\u001b[32m[05/16 12:34:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 341/2065. 2.0473 s / img. ETA=0:58:53\n",
      "\u001b[32m[05/16 12:34:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 344/2065. 2.0473 s / img. ETA=0:58:47\n",
      "\u001b[32m[05/16 12:34:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 347/2065. 2.0473 s / img. ETA=0:58:41\n",
      "\u001b[32m[05/16 12:35:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 350/2065. 2.0473 s / img. ETA=0:58:34\n",
      "\u001b[32m[05/16 12:35:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 353/2065. 2.0473 s / img. ETA=0:58:28\n",
      "\u001b[32m[05/16 12:35:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 356/2065. 2.0473 s / img. ETA=0:58:22\n",
      "\u001b[32m[05/16 12:35:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 359/2065. 2.0473 s / img. ETA=0:58:16\n",
      "\u001b[32m[05/16 12:35:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 362/2065. 2.0472 s / img. ETA=0:58:10\n",
      "\u001b[32m[05/16 12:35:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 365/2065. 2.0472 s / img. ETA=0:58:04\n",
      "\u001b[32m[05/16 12:35:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 368/2065. 2.0472 s / img. ETA=0:57:58\n",
      "\u001b[32m[05/16 12:35:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 371/2065. 2.0472 s / img. ETA=0:57:51\n",
      "\u001b[32m[05/16 12:35:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 374/2065. 2.0472 s / img. ETA=0:57:45\n",
      "\u001b[32m[05/16 12:35:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 377/2065. 2.0472 s / img. ETA=0:57:39\n",
      "\u001b[32m[05/16 12:36:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 380/2065. 2.0472 s / img. ETA=0:57:33\n",
      "\u001b[32m[05/16 12:36:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 383/2065. 2.0472 s / img. ETA=0:57:27\n",
      "\u001b[32m[05/16 12:36:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 386/2065. 2.0472 s / img. ETA=0:57:21\n",
      "\u001b[32m[05/16 12:36:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 389/2065. 2.0472 s / img. ETA=0:57:14\n",
      "\u001b[32m[05/16 12:36:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 392/2065. 2.0472 s / img. ETA=0:57:08\n",
      "\u001b[32m[05/16 12:36:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 395/2065. 2.0472 s / img. ETA=0:57:02\n",
      "\u001b[32m[05/16 12:36:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 398/2065. 2.0473 s / img. ETA=0:56:56\n",
      "\u001b[32m[05/16 12:36:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 401/2065. 2.0473 s / img. ETA=0:56:50\n",
      "\u001b[32m[05/16 12:36:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 404/2065. 2.0472 s / img. ETA=0:56:44\n",
      "\u001b[32m[05/16 12:37:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 407/2065. 2.0473 s / img. ETA=0:56:38\n",
      "\u001b[32m[05/16 12:37:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 410/2065. 2.0473 s / img. ETA=0:56:32\n",
      "\u001b[32m[05/16 12:37:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 413/2065. 2.0473 s / img. ETA=0:56:25\n",
      "\u001b[32m[05/16 12:37:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 416/2065. 2.0473 s / img. ETA=0:56:19\n",
      "\u001b[32m[05/16 12:37:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 419/2065. 2.0473 s / img. ETA=0:56:13\n",
      "\u001b[32m[05/16 12:37:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 422/2065. 2.0473 s / img. ETA=0:56:07\n",
      "\u001b[32m[05/16 12:37:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 425/2065. 2.0473 s / img. ETA=0:56:01\n",
      "\u001b[32m[05/16 12:37:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 428/2065. 2.0473 s / img. ETA=0:55:55\n",
      "\u001b[32m[05/16 12:37:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 431/2065. 2.0472 s / img. ETA=0:55:48\n",
      "\u001b[32m[05/16 12:37:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 434/2065. 2.0472 s / img. ETA=0:55:42\n",
      "\u001b[32m[05/16 12:38:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 437/2065. 2.0473 s / img. ETA=0:55:36\n",
      "\u001b[32m[05/16 12:38:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 440/2065. 2.0473 s / img. ETA=0:55:30\n",
      "\u001b[32m[05/16 12:38:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 443/2065. 2.0473 s / img. ETA=0:55:24\n",
      "\u001b[32m[05/16 12:38:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 446/2065. 2.0473 s / img. ETA=0:55:18\n",
      "\u001b[32m[05/16 12:38:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 449/2065. 2.0473 s / img. ETA=0:55:12\n",
      "\u001b[32m[05/16 12:38:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 452/2065. 2.0473 s / img. ETA=0:55:06\n",
      "\u001b[32m[05/16 12:38:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 455/2065. 2.0473 s / img. ETA=0:54:59\n",
      "\u001b[32m[05/16 12:38:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 458/2065. 2.0473 s / img. ETA=0:54:53\n",
      "\u001b[32m[05/16 12:38:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 461/2065. 2.0473 s / img. ETA=0:54:47\n",
      "\u001b[32m[05/16 12:38:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 464/2065. 2.0473 s / img. ETA=0:54:41\n",
      "\u001b[32m[05/16 12:39:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 467/2065. 2.0473 s / img. ETA=0:54:35\n",
      "\u001b[32m[05/16 12:39:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 470/2065. 2.0473 s / img. ETA=0:54:29\n",
      "\u001b[32m[05/16 12:39:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 473/2065. 2.0473 s / img. ETA=0:54:22\n",
      "\u001b[32m[05/16 12:39:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 476/2065. 2.0473 s / img. ETA=0:54:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 12:39:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 479/2065. 2.0473 s / img. ETA=0:54:10\n",
      "\u001b[32m[05/16 12:39:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 482/2065. 2.0472 s / img. ETA=0:54:04\n",
      "\u001b[32m[05/16 12:39:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 485/2065. 2.0473 s / img. ETA=0:53:58\n",
      "\u001b[32m[05/16 12:39:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 488/2065. 2.0473 s / img. ETA=0:53:52\n",
      "\u001b[32m[05/16 12:39:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 491/2065. 2.0473 s / img. ETA=0:53:46\n",
      "\u001b[32m[05/16 12:39:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 494/2065. 2.0473 s / img. ETA=0:53:39\n",
      "\u001b[32m[05/16 12:40:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 497/2065. 2.0473 s / img. ETA=0:53:33\n",
      "\u001b[32m[05/16 12:40:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 500/2065. 2.0474 s / img. ETA=0:53:27\n",
      "\u001b[32m[05/16 12:40:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 503/2065. 2.0474 s / img. ETA=0:53:21\n",
      "\u001b[32m[05/16 12:40:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 506/2065. 2.0474 s / img. ETA=0:53:15\n",
      "\u001b[32m[05/16 12:40:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 509/2065. 2.0474 s / img. ETA=0:53:09\n",
      "\u001b[32m[05/16 12:40:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 512/2065. 2.0474 s / img. ETA=0:53:03\n",
      "\u001b[32m[05/16 12:40:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 515/2065. 2.0473 s / img. ETA=0:52:56\n",
      "\u001b[32m[05/16 12:40:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 518/2065. 2.0473 s / img. ETA=0:52:50\n",
      "\u001b[32m[05/16 12:40:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 521/2065. 2.0474 s / img. ETA=0:52:44\n",
      "\u001b[32m[05/16 12:41:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 524/2065. 2.0473 s / img. ETA=0:52:38\n",
      "\u001b[32m[05/16 12:41:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 527/2065. 2.0474 s / img. ETA=0:52:32\n",
      "\u001b[32m[05/16 12:41:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 530/2065. 2.0474 s / img. ETA=0:52:26\n",
      "\u001b[32m[05/16 12:41:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 533/2065. 2.0474 s / img. ETA=0:52:20\n",
      "\u001b[32m[05/16 12:41:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 536/2065. 2.0474 s / img. ETA=0:52:14\n",
      "\u001b[32m[05/16 12:41:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 539/2065. 2.0474 s / img. ETA=0:52:07\n",
      "\u001b[32m[05/16 12:41:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 542/2065. 2.0474 s / img. ETA=0:52:01\n",
      "\u001b[32m[05/16 12:41:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 545/2065. 2.0474 s / img. ETA=0:51:55\n",
      "\u001b[32m[05/16 12:41:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 548/2065. 2.0474 s / img. ETA=0:51:49\n",
      "\u001b[32m[05/16 12:41:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 551/2065. 2.0474 s / img. ETA=0:51:43\n",
      "\u001b[32m[05/16 12:42:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 554/2065. 2.0474 s / img. ETA=0:51:37\n",
      "\u001b[32m[05/16 12:42:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 557/2065. 2.0474 s / img. ETA=0:51:30\n",
      "\u001b[32m[05/16 12:42:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 560/2065. 2.0474 s / img. ETA=0:51:24\n",
      "\u001b[32m[05/16 12:42:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 563/2065. 2.0473 s / img. ETA=0:51:18\n",
      "\u001b[32m[05/16 12:42:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 566/2065. 2.0473 s / img. ETA=0:51:12\n",
      "\u001b[32m[05/16 12:42:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 569/2065. 2.0473 s / img. ETA=0:51:06\n",
      "\u001b[32m[05/16 12:42:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 572/2065. 2.0473 s / img. ETA=0:51:00\n",
      "\u001b[32m[05/16 12:42:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 575/2065. 2.0473 s / img. ETA=0:50:53\n",
      "\u001b[32m[05/16 12:42:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 578/2065. 2.0474 s / img. ETA=0:50:47\n",
      "\u001b[32m[05/16 12:42:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 581/2065. 2.0474 s / img. ETA=0:50:41\n",
      "\u001b[32m[05/16 12:43:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 584/2065. 2.0473 s / img. ETA=0:50:35\n",
      "\u001b[32m[05/16 12:43:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 587/2065. 2.0473 s / img. ETA=0:50:29\n",
      "\u001b[32m[05/16 12:43:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 590/2065. 2.0473 s / img. ETA=0:50:23\n",
      "\u001b[32m[05/16 12:43:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 593/2065. 2.0474 s / img. ETA=0:50:17\n",
      "\u001b[32m[05/16 12:43:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 596/2065. 2.0474 s / img. ETA=0:50:10\n",
      "\u001b[32m[05/16 12:43:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 599/2065. 2.0474 s / img. ETA=0:50:04\n",
      "\u001b[32m[05/16 12:43:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 602/2065. 2.0474 s / img. ETA=0:49:58\n",
      "\u001b[32m[05/16 12:43:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 605/2065. 2.0474 s / img. ETA=0:49:52\n",
      "\u001b[32m[05/16 12:43:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 608/2065. 2.0474 s / img. ETA=0:49:46\n",
      "\u001b[32m[05/16 12:43:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 611/2065. 2.0474 s / img. ETA=0:49:40\n",
      "\u001b[32m[05/16 12:44:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 614/2065. 2.0474 s / img. ETA=0:49:34\n",
      "\u001b[32m[05/16 12:44:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 617/2065. 2.0474 s / img. ETA=0:49:27\n",
      "\u001b[32m[05/16 12:44:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 620/2065. 2.0474 s / img. ETA=0:49:21\n",
      "\u001b[32m[05/16 12:44:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 623/2065. 2.0474 s / img. ETA=0:49:15\n",
      "\u001b[32m[05/16 12:44:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 626/2065. 2.0474 s / img. ETA=0:49:09\n",
      "\u001b[32m[05/16 12:44:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 629/2065. 2.0474 s / img. ETA=0:49:03\n",
      "\u001b[32m[05/16 12:44:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 632/2065. 2.0474 s / img. ETA=0:48:57\n",
      "\u001b[32m[05/16 12:44:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 635/2065. 2.0474 s / img. ETA=0:48:51\n",
      "\u001b[32m[05/16 12:44:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 638/2065. 2.0474 s / img. ETA=0:48:45\n",
      "\u001b[32m[05/16 12:45:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 641/2065. 2.0475 s / img. ETA=0:48:38\n",
      "\u001b[32m[05/16 12:45:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 644/2065. 2.0474 s / img. ETA=0:48:32\n",
      "\u001b[32m[05/16 12:45:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 647/2065. 2.0475 s / img. ETA=0:48:26\n",
      "\u001b[32m[05/16 12:45:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 650/2065. 2.0475 s / img. ETA=0:48:20\n",
      "\u001b[32m[05/16 12:45:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 653/2065. 2.0475 s / img. ETA=0:48:14\n",
      "\u001b[32m[05/16 12:45:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 656/2065. 2.0475 s / img. ETA=0:48:08\n",
      "\u001b[32m[05/16 12:45:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 659/2065. 2.0474 s / img. ETA=0:48:01\n",
      "\u001b[32m[05/16 12:45:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 662/2065. 2.0474 s / img. ETA=0:47:55\n",
      "\u001b[32m[05/16 12:45:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 665/2065. 2.0474 s / img. ETA=0:47:49\n",
      "\u001b[32m[05/16 12:45:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 668/2065. 2.0474 s / img. ETA=0:47:43\n",
      "\u001b[32m[05/16 12:46:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 671/2065. 2.0474 s / img. ETA=0:47:37\n",
      "\u001b[32m[05/16 12:46:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 674/2065. 2.0474 s / img. ETA=0:47:31\n",
      "\u001b[32m[05/16 12:46:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 677/2065. 2.0474 s / img. ETA=0:47:24\n",
      "\u001b[32m[05/16 12:46:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 680/2065. 2.0474 s / img. ETA=0:47:18\n",
      "\u001b[32m[05/16 12:46:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 683/2065. 2.0474 s / img. ETA=0:47:12\n",
      "\u001b[32m[05/16 12:46:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 686/2065. 2.0474 s / img. ETA=0:47:06\n",
      "\u001b[32m[05/16 12:46:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 689/2065. 2.0474 s / img. ETA=0:47:00\n",
      "\u001b[32m[05/16 12:46:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 692/2065. 2.0474 s / img. ETA=0:46:54\n",
      "\u001b[32m[05/16 12:46:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 695/2065. 2.0474 s / img. ETA=0:46:48\n",
      "\u001b[32m[05/16 12:46:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 698/2065. 2.0474 s / img. ETA=0:46:41\n",
      "\u001b[32m[05/16 12:47:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 701/2065. 2.0474 s / img. ETA=0:46:35\n",
      "\u001b[32m[05/16 12:47:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 704/2065. 2.0474 s / img. ETA=0:46:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 12:47:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 707/2065. 2.0474 s / img. ETA=0:46:23\n",
      "\u001b[32m[05/16 12:47:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 710/2065. 2.0474 s / img. ETA=0:46:17\n",
      "\u001b[32m[05/16 12:47:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 713/2065. 2.0474 s / img. ETA=0:46:11\n",
      "\u001b[32m[05/16 12:47:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 716/2065. 2.0474 s / img. ETA=0:46:05\n",
      "\u001b[32m[05/16 12:47:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 719/2065. 2.0474 s / img. ETA=0:45:58\n",
      "\u001b[32m[05/16 12:47:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 722/2065. 2.0474 s / img. ETA=0:45:52\n",
      "\u001b[32m[05/16 12:47:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 725/2065. 2.0474 s / img. ETA=0:45:46\n",
      "\u001b[32m[05/16 12:47:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 728/2065. 2.0474 s / img. ETA=0:45:40\n",
      "\u001b[32m[05/16 12:48:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 731/2065. 2.0474 s / img. ETA=0:45:34\n",
      "\u001b[32m[05/16 12:48:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 734/2065. 2.0474 s / img. ETA=0:45:28\n",
      "\u001b[32m[05/16 12:48:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 737/2065. 2.0474 s / img. ETA=0:45:21\n",
      "\u001b[32m[05/16 12:48:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 740/2065. 2.0474 s / img. ETA=0:45:15\n",
      "\u001b[32m[05/16 12:48:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 743/2065. 2.0474 s / img. ETA=0:45:09\n",
      "\u001b[32m[05/16 12:48:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 746/2065. 2.0474 s / img. ETA=0:45:03\n",
      "\u001b[32m[05/16 12:48:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 749/2065. 2.0474 s / img. ETA=0:44:57\n",
      "\u001b[32m[05/16 12:48:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 752/2065. 2.0474 s / img. ETA=0:44:51\n",
      "\u001b[32m[05/16 12:48:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 755/2065. 2.0473 s / img. ETA=0:44:45\n",
      "\u001b[32m[05/16 12:48:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 758/2065. 2.0474 s / img. ETA=0:44:38\n",
      "\u001b[32m[05/16 12:49:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 761/2065. 2.0474 s / img. ETA=0:44:32\n",
      "\u001b[32m[05/16 12:49:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 764/2065. 2.0474 s / img. ETA=0:44:26\n",
      "\u001b[32m[05/16 12:49:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 767/2065. 2.0474 s / img. ETA=0:44:20\n",
      "\u001b[32m[05/16 12:49:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 770/2065. 2.0474 s / img. ETA=0:44:14\n",
      "\u001b[32m[05/16 12:49:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 773/2065. 2.0474 s / img. ETA=0:44:08\n",
      "\u001b[32m[05/16 12:49:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 776/2065. 2.0474 s / img. ETA=0:44:02\n",
      "\u001b[32m[05/16 12:49:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 779/2065. 2.0474 s / img. ETA=0:43:55\n",
      "\u001b[32m[05/16 12:49:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 782/2065. 2.0474 s / img. ETA=0:43:49\n",
      "\u001b[32m[05/16 12:49:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 785/2065. 2.0473 s / img. ETA=0:43:43\n",
      "\u001b[32m[05/16 12:50:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 788/2065. 2.0473 s / img. ETA=0:43:37\n",
      "\u001b[32m[05/16 12:50:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 791/2065. 2.0474 s / img. ETA=0:43:31\n",
      "\u001b[32m[05/16 12:50:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 794/2065. 2.0473 s / img. ETA=0:43:25\n",
      "\u001b[32m[05/16 12:50:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 797/2065. 2.0473 s / img. ETA=0:43:18\n",
      "\u001b[32m[05/16 12:50:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 800/2065. 2.0473 s / img. ETA=0:43:12\n",
      "\u001b[32m[05/16 12:50:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 803/2065. 2.0473 s / img. ETA=0:43:06\n",
      "\u001b[32m[05/16 12:50:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 806/2065. 2.0473 s / img. ETA=0:43:00\n",
      "\u001b[32m[05/16 12:50:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 809/2065. 2.0473 s / img. ETA=0:42:54\n",
      "\u001b[32m[05/16 12:50:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 812/2065. 2.0473 s / img. ETA=0:42:48\n",
      "\u001b[32m[05/16 12:50:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 815/2065. 2.0473 s / img. ETA=0:42:41\n",
      "\u001b[32m[05/16 12:51:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 818/2065. 2.0473 s / img. ETA=0:42:35\n",
      "\u001b[32m[05/16 12:51:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 821/2065. 2.0473 s / img. ETA=0:42:29\n",
      "\u001b[32m[05/16 12:51:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 824/2065. 2.0473 s / img. ETA=0:42:23\n",
      "\u001b[32m[05/16 12:51:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 827/2065. 2.0473 s / img. ETA=0:42:17\n",
      "\u001b[32m[05/16 12:51:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 830/2065. 2.0473 s / img. ETA=0:42:11\n",
      "\u001b[32m[05/16 12:51:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 833/2065. 2.0473 s / img. ETA=0:42:05\n",
      "\u001b[32m[05/16 12:51:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 836/2065. 2.0473 s / img. ETA=0:41:58\n",
      "\u001b[32m[05/16 12:51:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 839/2065. 2.0473 s / img. ETA=0:41:52\n",
      "\u001b[32m[05/16 12:51:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 842/2065. 2.0473 s / img. ETA=0:41:46\n",
      "\u001b[32m[05/16 12:51:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 845/2065. 2.0473 s / img. ETA=0:41:40\n",
      "\u001b[32m[05/16 12:52:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 848/2065. 2.0473 s / img. ETA=0:41:34\n",
      "\u001b[32m[05/16 12:52:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 851/2065. 2.0473 s / img. ETA=0:41:28\n",
      "\u001b[32m[05/16 12:52:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 854/2065. 2.0473 s / img. ETA=0:41:22\n",
      "\u001b[32m[05/16 12:52:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 857/2065. 2.0473 s / img. ETA=0:41:15\n",
      "\u001b[32m[05/16 12:52:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 860/2065. 2.0473 s / img. ETA=0:41:09\n",
      "\u001b[32m[05/16 12:52:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 863/2065. 2.0473 s / img. ETA=0:41:03\n",
      "\u001b[32m[05/16 12:52:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 866/2065. 2.0473 s / img. ETA=0:40:57\n",
      "\u001b[32m[05/16 12:52:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 869/2065. 2.0473 s / img. ETA=0:40:51\n",
      "\u001b[32m[05/16 12:52:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 872/2065. 2.0473 s / img. ETA=0:40:45\n",
      "\u001b[32m[05/16 12:52:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 875/2065. 2.0473 s / img. ETA=0:40:39\n",
      "\u001b[32m[05/16 12:53:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 878/2065. 2.0473 s / img. ETA=0:40:32\n",
      "\u001b[32m[05/16 12:53:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 881/2065. 2.0473 s / img. ETA=0:40:26\n",
      "\u001b[32m[05/16 12:53:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 884/2065. 2.0473 s / img. ETA=0:40:20\n",
      "\u001b[32m[05/16 12:53:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 887/2065. 2.0473 s / img. ETA=0:40:14\n",
      "\u001b[32m[05/16 12:53:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 890/2065. 2.0473 s / img. ETA=0:40:08\n",
      "\u001b[32m[05/16 12:53:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 893/2065. 2.0473 s / img. ETA=0:40:02\n",
      "\u001b[32m[05/16 12:53:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 896/2065. 2.0473 s / img. ETA=0:39:56\n",
      "\u001b[32m[05/16 12:53:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 899/2065. 2.0473 s / img. ETA=0:39:49\n",
      "\u001b[32m[05/16 12:53:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 902/2065. 2.0473 s / img. ETA=0:39:43\n",
      "\u001b[32m[05/16 12:54:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 905/2065. 2.0473 s / img. ETA=0:39:37\n",
      "\u001b[32m[05/16 12:54:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 908/2065. 2.0473 s / img. ETA=0:39:31\n",
      "\u001b[32m[05/16 12:54:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 911/2065. 2.0474 s / img. ETA=0:39:25\n",
      "\u001b[32m[05/16 12:54:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 914/2065. 2.0474 s / img. ETA=0:39:19\n",
      "\u001b[32m[05/16 12:54:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 917/2065. 2.0473 s / img. ETA=0:39:12\n",
      "\u001b[32m[05/16 12:54:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 920/2065. 2.0473 s / img. ETA=0:39:06\n",
      "\u001b[32m[05/16 12:54:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 923/2065. 2.0473 s / img. ETA=0:39:00\n",
      "\u001b[32m[05/16 12:54:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 926/2065. 2.0473 s / img. ETA=0:38:54\n",
      "\u001b[32m[05/16 12:54:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 929/2065. 2.0473 s / img. ETA=0:38:48\n",
      "\u001b[32m[05/16 12:54:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 932/2065. 2.0474 s / img. ETA=0:38:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 12:55:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 935/2065. 2.0473 s / img. ETA=0:38:36\n",
      "\u001b[32m[05/16 12:55:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 938/2065. 2.0473 s / img. ETA=0:38:29\n",
      "\u001b[32m[05/16 12:55:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 941/2065. 2.0474 s / img. ETA=0:38:23\n",
      "\u001b[32m[05/16 12:55:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 944/2065. 2.0474 s / img. ETA=0:38:17\n",
      "\u001b[32m[05/16 12:55:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 947/2065. 2.0474 s / img. ETA=0:38:11\n",
      "\u001b[32m[05/16 12:55:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 950/2065. 2.0473 s / img. ETA=0:38:05\n",
      "\u001b[32m[05/16 12:55:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 953/2065. 2.0473 s / img. ETA=0:37:59\n",
      "\u001b[32m[05/16 12:55:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 956/2065. 2.0474 s / img. ETA=0:37:53\n",
      "\u001b[32m[05/16 12:55:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 959/2065. 2.0474 s / img. ETA=0:37:46\n",
      "\u001b[32m[05/16 12:55:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 962/2065. 2.0474 s / img. ETA=0:37:40\n",
      "\u001b[32m[05/16 12:56:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 965/2065. 2.0474 s / img. ETA=0:37:34\n",
      "\u001b[32m[05/16 12:56:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 968/2065. 2.0474 s / img. ETA=0:37:28\n",
      "\u001b[32m[05/16 12:56:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 971/2065. 2.0474 s / img. ETA=0:37:22\n",
      "\u001b[32m[05/16 12:56:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 974/2065. 2.0474 s / img. ETA=0:37:16\n",
      "\u001b[32m[05/16 12:56:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 977/2065. 2.0474 s / img. ETA=0:37:10\n",
      "\u001b[32m[05/16 12:56:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 980/2065. 2.0474 s / img. ETA=0:37:03\n",
      "\u001b[32m[05/16 12:56:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 983/2065. 2.0474 s / img. ETA=0:36:57\n",
      "\u001b[32m[05/16 12:56:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 986/2065. 2.0474 s / img. ETA=0:36:51\n",
      "\u001b[32m[05/16 12:56:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 989/2065. 2.0474 s / img. ETA=0:36:45\n",
      "\u001b[32m[05/16 12:56:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 992/2065. 2.0474 s / img. ETA=0:36:39\n",
      "\u001b[32m[05/16 12:57:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 995/2065. 2.0474 s / img. ETA=0:36:33\n",
      "\u001b[32m[05/16 12:57:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 998/2065. 2.0474 s / img. ETA=0:36:26\n",
      "\u001b[32m[05/16 12:57:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 1001/2065. 2.0474 s / img. ETA=0:36:20\n",
      "\u001b[32m[05/16 12:57:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 1004/2065. 2.0474 s / img. ETA=0:36:14\n",
      "\u001b[32m[05/16 12:57:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 1007/2065. 2.0474 s / img. ETA=0:36:08\n",
      "\u001b[32m[05/16 12:57:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 1010/2065. 2.0474 s / img. ETA=0:36:02\n",
      "\u001b[32m[05/16 12:57:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 1013/2065. 2.0474 s / img. ETA=0:35:56\n",
      "\u001b[32m[05/16 12:57:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 1016/2065. 2.0474 s / img. ETA=0:35:50\n",
      "\u001b[32m[05/16 12:57:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 1019/2065. 2.0474 s / img. ETA=0:35:43\n",
      "\u001b[32m[05/16 12:58:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 1022/2065. 2.0474 s / img. ETA=0:35:37\n",
      "\u001b[32m[05/16 12:58:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 1025/2065. 2.0474 s / img. ETA=0:35:31\n",
      "\u001b[32m[05/16 12:58:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 1028/2065. 2.0474 s / img. ETA=0:35:25\n",
      "\u001b[32m[05/16 12:58:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 1031/2065. 2.0474 s / img. ETA=0:35:19\n",
      "\u001b[32m[05/16 12:58:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 1034/2065. 2.0474 s / img. ETA=0:35:13\n",
      "\u001b[32m[05/16 12:58:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 1037/2065. 2.0474 s / img. ETA=0:35:07\n",
      "\u001b[32m[05/16 12:58:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 1040/2065. 2.0474 s / img. ETA=0:35:00\n",
      "\u001b[32m[05/16 12:58:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 1043/2065. 2.0474 s / img. ETA=0:34:54\n",
      "\u001b[32m[05/16 12:58:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 1046/2065. 2.0474 s / img. ETA=0:34:48\n",
      "\u001b[32m[05/16 12:58:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 1049/2065. 2.0474 s / img. ETA=0:34:42\n",
      "\u001b[32m[05/16 12:59:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 1052/2065. 2.0474 s / img. ETA=0:34:36\n",
      "\u001b[32m[05/16 12:59:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 1055/2065. 2.0474 s / img. ETA=0:34:30\n",
      "\u001b[32m[05/16 12:59:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 1058/2065. 2.0474 s / img. ETA=0:34:24\n",
      "\u001b[32m[05/16 12:59:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 1061/2065. 2.0474 s / img. ETA=0:34:17\n",
      "\u001b[32m[05/16 12:59:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 1064/2065. 2.0474 s / img. ETA=0:34:11\n",
      "\u001b[32m[05/16 12:59:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 1067/2065. 2.0474 s / img. ETA=0:34:05\n",
      "\u001b[32m[05/16 12:59:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 1070/2065. 2.0474 s / img. ETA=0:33:59\n",
      "\u001b[32m[05/16 12:59:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 1073/2065. 2.0474 s / img. ETA=0:33:53\n",
      "\u001b[32m[05/16 12:59:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 1076/2065. 2.0474 s / img. ETA=0:33:47\n",
      "\u001b[32m[05/16 12:59:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 1079/2065. 2.0474 s / img. ETA=0:33:41\n",
      "\u001b[32m[05/16 13:00:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 1082/2065. 2.0474 s / img. ETA=0:33:34\n",
      "\u001b[32m[05/16 13:00:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 1085/2065. 2.0474 s / img. ETA=0:33:28\n",
      "\u001b[32m[05/16 13:00:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 1088/2065. 2.0474 s / img. ETA=0:33:22\n",
      "\u001b[32m[05/16 13:00:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 1091/2065. 2.0474 s / img. ETA=0:33:16\n",
      "\u001b[32m[05/16 13:00:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 1094/2065. 2.0474 s / img. ETA=0:33:10\n",
      "\u001b[32m[05/16 13:00:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 1097/2065. 2.0474 s / img. ETA=0:33:04\n",
      "\u001b[32m[05/16 13:00:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 1100/2065. 2.0474 s / img. ETA=0:32:57\n",
      "\u001b[32m[05/16 13:00:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 1103/2065. 2.0474 s / img. ETA=0:32:51\n",
      "\u001b[32m[05/16 13:00:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 1106/2065. 2.0474 s / img. ETA=0:32:45\n",
      "\u001b[32m[05/16 13:00:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 1109/2065. 2.0474 s / img. ETA=0:32:39\n",
      "\u001b[32m[05/16 13:01:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 1112/2065. 2.0474 s / img. ETA=0:32:33\n",
      "\u001b[32m[05/16 13:01:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 1115/2065. 2.0474 s / img. ETA=0:32:27\n",
      "\u001b[32m[05/16 13:01:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 1118/2065. 2.0474 s / img. ETA=0:32:21\n",
      "\u001b[32m[05/16 13:01:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 1121/2065. 2.0474 s / img. ETA=0:32:14\n",
      "\u001b[32m[05/16 13:01:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 1124/2065. 2.0474 s / img. ETA=0:32:08\n",
      "\u001b[32m[05/16 13:01:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 1127/2065. 2.0474 s / img. ETA=0:32:02\n",
      "\u001b[32m[05/16 13:01:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 1130/2065. 2.0474 s / img. ETA=0:31:56\n",
      "\u001b[32m[05/16 13:01:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 1133/2065. 2.0474 s / img. ETA=0:31:50\n",
      "\u001b[32m[05/16 13:01:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 1136/2065. 2.0474 s / img. ETA=0:31:44\n",
      "\u001b[32m[05/16 13:02:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 1139/2065. 2.0474 s / img. ETA=0:31:38\n",
      "\u001b[32m[05/16 13:02:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 1142/2065. 2.0474 s / img. ETA=0:31:31\n",
      "\u001b[32m[05/16 13:02:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 1145/2065. 2.0474 s / img. ETA=0:31:25\n",
      "\u001b[32m[05/16 13:02:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 1148/2065. 2.0474 s / img. ETA=0:31:19\n",
      "\u001b[32m[05/16 13:02:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 1151/2065. 2.0474 s / img. ETA=0:31:13\n",
      "\u001b[32m[05/16 13:02:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 1154/2065. 2.0474 s / img. ETA=0:31:07\n",
      "\u001b[32m[05/16 13:02:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 1157/2065. 2.0474 s / img. ETA=0:31:01\n",
      "\u001b[32m[05/16 13:02:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 1160/2065. 2.0474 s / img. ETA=0:30:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 13:02:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 1163/2065. 2.0474 s / img. ETA=0:30:48\n",
      "\u001b[32m[05/16 13:02:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 1166/2065. 2.0474 s / img. ETA=0:30:42\n",
      "\u001b[32m[05/16 13:03:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 1169/2065. 2.0474 s / img. ETA=0:30:36\n",
      "\u001b[32m[05/16 13:03:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 1172/2065. 2.0474 s / img. ETA=0:30:30\n",
      "\u001b[32m[05/16 13:03:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 1175/2065. 2.0474 s / img. ETA=0:30:24\n",
      "\u001b[32m[05/16 13:03:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 1178/2065. 2.0474 s / img. ETA=0:30:18\n",
      "\u001b[32m[05/16 13:03:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 1181/2065. 2.0474 s / img. ETA=0:30:11\n",
      "\u001b[32m[05/16 13:03:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 1184/2065. 2.0474 s / img. ETA=0:30:05\n",
      "\u001b[32m[05/16 13:03:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 1187/2065. 2.0474 s / img. ETA=0:29:59\n",
      "\u001b[32m[05/16 13:03:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 1190/2065. 2.0474 s / img. ETA=0:29:53\n",
      "\u001b[32m[05/16 13:03:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 1193/2065. 2.0474 s / img. ETA=0:29:47\n",
      "\u001b[32m[05/16 13:03:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 1196/2065. 2.0474 s / img. ETA=0:29:41\n",
      "\u001b[32m[05/16 13:04:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 1199/2065. 2.0474 s / img. ETA=0:29:35\n",
      "\u001b[32m[05/16 13:04:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 1202/2065. 2.0474 s / img. ETA=0:29:28\n",
      "\u001b[32m[05/16 13:04:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 1205/2065. 2.0474 s / img. ETA=0:29:22\n",
      "\u001b[32m[05/16 13:04:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 1208/2065. 2.0474 s / img. ETA=0:29:16\n",
      "\u001b[32m[05/16 13:04:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 1211/2065. 2.0474 s / img. ETA=0:29:10\n",
      "\u001b[32m[05/16 13:04:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 1214/2065. 2.0474 s / img. ETA=0:29:04\n",
      "\u001b[32m[05/16 13:04:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 1217/2065. 2.0474 s / img. ETA=0:28:58\n",
      "\u001b[32m[05/16 13:04:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 1220/2065. 2.0474 s / img. ETA=0:28:52\n",
      "\u001b[32m[05/16 13:04:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 1223/2065. 2.0474 s / img. ETA=0:28:45\n",
      "\u001b[32m[05/16 13:04:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 1226/2065. 2.0474 s / img. ETA=0:28:39\n",
      "\u001b[32m[05/16 13:05:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 1229/2065. 2.0474 s / img. ETA=0:28:33\n",
      "\u001b[32m[05/16 13:05:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 1232/2065. 2.0474 s / img. ETA=0:28:27\n",
      "\u001b[32m[05/16 13:05:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 1235/2065. 2.0474 s / img. ETA=0:28:21\n",
      "\u001b[32m[05/16 13:05:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 1238/2065. 2.0474 s / img. ETA=0:28:15\n",
      "\u001b[32m[05/16 13:05:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 1241/2065. 2.0474 s / img. ETA=0:28:08\n",
      "\u001b[32m[05/16 13:05:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 1244/2065. 2.0474 s / img. ETA=0:28:02\n",
      "\u001b[32m[05/16 13:05:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 1247/2065. 2.0474 s / img. ETA=0:27:56\n",
      "\u001b[32m[05/16 13:05:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 1250/2065. 2.0474 s / img. ETA=0:27:50\n",
      "\u001b[32m[05/16 13:05:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 1253/2065. 2.0474 s / img. ETA=0:27:44\n",
      "\u001b[32m[05/16 13:06:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 1256/2065. 2.0474 s / img. ETA=0:27:38\n",
      "\u001b[32m[05/16 13:06:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 1259/2065. 2.0474 s / img. ETA=0:27:32\n",
      "\u001b[32m[05/16 13:06:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 1262/2065. 2.0474 s / img. ETA=0:27:25\n",
      "\u001b[32m[05/16 13:06:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 1265/2065. 2.0474 s / img. ETA=0:27:19\n",
      "\u001b[32m[05/16 13:06:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 1268/2065. 2.0474 s / img. ETA=0:27:13\n",
      "\u001b[32m[05/16 13:06:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 1271/2065. 2.0474 s / img. ETA=0:27:07\n",
      "\u001b[32m[05/16 13:06:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 1274/2065. 2.0474 s / img. ETA=0:27:01\n",
      "\u001b[32m[05/16 13:06:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 1277/2065. 2.0474 s / img. ETA=0:26:55\n",
      "\u001b[32m[05/16 13:06:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 1280/2065. 2.0474 s / img. ETA=0:26:49\n",
      "\u001b[32m[05/16 13:06:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 1283/2065. 2.0474 s / img. ETA=0:26:42\n",
      "\u001b[32m[05/16 13:07:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 1286/2065. 2.0474 s / img. ETA=0:26:36\n",
      "\u001b[32m[05/16 13:07:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 1289/2065. 2.0474 s / img. ETA=0:26:30\n",
      "\u001b[32m[05/16 13:07:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 1292/2065. 2.0474 s / img. ETA=0:26:24\n",
      "\u001b[32m[05/16 13:07:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 1295/2065. 2.0474 s / img. ETA=0:26:18\n",
      "\u001b[32m[05/16 13:07:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 1298/2065. 2.0474 s / img. ETA=0:26:12\n",
      "\u001b[32m[05/16 13:07:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 1301/2065. 2.0474 s / img. ETA=0:26:06\n",
      "\u001b[32m[05/16 13:07:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 1304/2065. 2.0474 s / img. ETA=0:25:59\n",
      "\u001b[32m[05/16 13:07:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 1307/2065. 2.0474 s / img. ETA=0:25:53\n",
      "\u001b[32m[05/16 13:07:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 1310/2065. 2.0475 s / img. ETA=0:25:47\n",
      "\u001b[32m[05/16 13:07:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 1313/2065. 2.0475 s / img. ETA=0:25:41\n",
      "\u001b[32m[05/16 13:08:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 1316/2065. 2.0475 s / img. ETA=0:25:35\n",
      "\u001b[32m[05/16 13:08:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 1319/2065. 2.0474 s / img. ETA=0:25:29\n",
      "\u001b[32m[05/16 13:08:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 1322/2065. 2.0474 s / img. ETA=0:25:22\n",
      "\u001b[32m[05/16 13:08:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 1325/2065. 2.0474 s / img. ETA=0:25:16\n",
      "\u001b[32m[05/16 13:08:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 1328/2065. 2.0474 s / img. ETA=0:25:10\n",
      "\u001b[32m[05/16 13:08:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 1331/2065. 2.0474 s / img. ETA=0:25:04\n",
      "\u001b[32m[05/16 13:08:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 1334/2065. 2.0474 s / img. ETA=0:24:58\n",
      "\u001b[32m[05/16 13:08:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 1337/2065. 2.0475 s / img. ETA=0:24:52\n",
      "\u001b[32m[05/16 13:08:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 1340/2065. 2.0475 s / img. ETA=0:24:46\n",
      "\u001b[32m[05/16 13:08:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 1343/2065. 2.0475 s / img. ETA=0:24:39\n",
      "\u001b[32m[05/16 13:09:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 1346/2065. 2.0474 s / img. ETA=0:24:33\n",
      "\u001b[32m[05/16 13:09:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 1349/2065. 2.0474 s / img. ETA=0:24:27\n",
      "\u001b[32m[05/16 13:09:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 1352/2065. 2.0474 s / img. ETA=0:24:21\n",
      "\u001b[32m[05/16 13:09:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 1355/2065. 2.0474 s / img. ETA=0:24:15\n",
      "\u001b[32m[05/16 13:09:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 1358/2065. 2.0474 s / img. ETA=0:24:09\n",
      "\u001b[32m[05/16 13:09:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 1361/2065. 2.0475 s / img. ETA=0:24:03\n",
      "\u001b[32m[05/16 13:09:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 1364/2065. 2.0475 s / img. ETA=0:23:56\n",
      "\u001b[32m[05/16 13:09:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 1367/2065. 2.0475 s / img. ETA=0:23:50\n",
      "\u001b[32m[05/16 13:09:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 1370/2065. 2.0475 s / img. ETA=0:23:44\n",
      "\u001b[32m[05/16 13:10:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 1373/2065. 2.0475 s / img. ETA=0:23:38\n",
      "\u001b[32m[05/16 13:10:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 1376/2065. 2.0475 s / img. ETA=0:23:32\n",
      "\u001b[32m[05/16 13:10:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 1379/2065. 2.0475 s / img. ETA=0:23:26\n",
      "\u001b[32m[05/16 13:10:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 1382/2065. 2.0474 s / img. ETA=0:23:19\n",
      "\u001b[32m[05/16 13:10:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 1385/2065. 2.0475 s / img. ETA=0:23:13\n",
      "\u001b[32m[05/16 13:10:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 1388/2065. 2.0475 s / img. ETA=0:23:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 13:10:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 1391/2065. 2.0475 s / img. ETA=0:23:01\n",
      "\u001b[32m[05/16 13:10:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 1394/2065. 2.0475 s / img. ETA=0:22:55\n",
      "\u001b[32m[05/16 13:10:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 1397/2065. 2.0475 s / img. ETA=0:22:49\n",
      "\u001b[32m[05/16 13:10:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 1400/2065. 2.0475 s / img. ETA=0:22:43\n",
      "\u001b[32m[05/16 13:11:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 1403/2065. 2.0475 s / img. ETA=0:22:36\n",
      "\u001b[32m[05/16 13:11:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 1406/2065. 2.0475 s / img. ETA=0:22:30\n",
      "\u001b[32m[05/16 13:11:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 1409/2065. 2.0475 s / img. ETA=0:22:24\n",
      "\u001b[32m[05/16 13:11:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 1412/2065. 2.0475 s / img. ETA=0:22:18\n",
      "\u001b[32m[05/16 13:11:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 1415/2065. 2.0475 s / img. ETA=0:22:12\n",
      "\u001b[32m[05/16 13:11:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 1418/2065. 2.0475 s / img. ETA=0:22:06\n",
      "\u001b[32m[05/16 13:11:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 1421/2065. 2.0475 s / img. ETA=0:22:00\n",
      "\u001b[32m[05/16 13:11:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 1424/2065. 2.0475 s / img. ETA=0:21:53\n",
      "\u001b[32m[05/16 13:11:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 1427/2065. 2.0475 s / img. ETA=0:21:47\n",
      "\u001b[32m[05/16 13:11:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 1430/2065. 2.0475 s / img. ETA=0:21:41\n",
      "\u001b[32m[05/16 13:12:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 1433/2065. 2.0475 s / img. ETA=0:21:35\n",
      "\u001b[32m[05/16 13:12:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 1436/2065. 2.0475 s / img. ETA=0:21:29\n",
      "\u001b[32m[05/16 13:12:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 1439/2065. 2.0475 s / img. ETA=0:21:23\n",
      "\u001b[32m[05/16 13:12:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 1442/2065. 2.0475 s / img. ETA=0:21:17\n",
      "\u001b[32m[05/16 13:12:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 1445/2065. 2.0475 s / img. ETA=0:21:10\n",
      "\u001b[32m[05/16 13:12:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 1448/2065. 2.0475 s / img. ETA=0:21:04\n",
      "\u001b[32m[05/16 13:12:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 1451/2065. 2.0475 s / img. ETA=0:20:58\n",
      "\u001b[32m[05/16 13:12:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 1454/2065. 2.0475 s / img. ETA=0:20:52\n",
      "\u001b[32m[05/16 13:12:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 1457/2065. 2.0475 s / img. ETA=0:20:46\n",
      "\u001b[32m[05/16 13:12:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 1460/2065. 2.0475 s / img. ETA=0:20:40\n",
      "\u001b[32m[05/16 13:13:05 d2.evaluation.evaluator:197]: \u001b[0mInference done 1463/2065. 2.0475 s / img. ETA=0:20:33\n",
      "\u001b[32m[05/16 13:13:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 1466/2065. 2.0475 s / img. ETA=0:20:27\n",
      "\u001b[32m[05/16 13:13:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 1469/2065. 2.0475 s / img. ETA=0:20:21\n",
      "\u001b[32m[05/16 13:13:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 1472/2065. 2.0475 s / img. ETA=0:20:15\n",
      "\u001b[32m[05/16 13:13:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 1475/2065. 2.0475 s / img. ETA=0:20:09\n",
      "\u001b[32m[05/16 13:13:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 1478/2065. 2.0475 s / img. ETA=0:20:03\n",
      "\u001b[32m[05/16 13:13:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 1481/2065. 2.0475 s / img. ETA=0:19:57\n",
      "\u001b[32m[05/16 13:13:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 1484/2065. 2.0475 s / img. ETA=0:19:50\n",
      "\u001b[32m[05/16 13:13:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 1487/2065. 2.0475 s / img. ETA=0:19:44\n",
      "\u001b[32m[05/16 13:14:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 1490/2065. 2.0475 s / img. ETA=0:19:38\n",
      "\u001b[32m[05/16 13:14:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 1493/2065. 2.0475 s / img. ETA=0:19:32\n",
      "\u001b[32m[05/16 13:14:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 1496/2065. 2.0475 s / img. ETA=0:19:26\n",
      "\u001b[32m[05/16 13:14:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 1499/2065. 2.0475 s / img. ETA=0:19:20\n",
      "\u001b[32m[05/16 13:14:25 d2.evaluation.evaluator:197]: \u001b[0mInference done 1502/2065. 2.0475 s / img. ETA=0:19:14\n",
      "\u001b[32m[05/16 13:14:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 1505/2065. 2.0475 s / img. ETA=0:19:07\n",
      "\u001b[32m[05/16 13:14:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 1508/2065. 2.0475 s / img. ETA=0:19:01\n",
      "\u001b[32m[05/16 13:14:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 1511/2065. 2.0475 s / img. ETA=0:18:55\n",
      "\u001b[32m[05/16 13:14:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 1514/2065. 2.0475 s / img. ETA=0:18:49\n",
      "\u001b[32m[05/16 13:14:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 1517/2065. 2.0475 s / img. ETA=0:18:43\n",
      "\u001b[32m[05/16 13:15:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 1520/2065. 2.0475 s / img. ETA=0:18:37\n",
      "\u001b[32m[05/16 13:15:08 d2.evaluation.evaluator:197]: \u001b[0mInference done 1523/2065. 2.0475 s / img. ETA=0:18:31\n",
      "\u001b[32m[05/16 13:15:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 1526/2065. 2.0475 s / img. ETA=0:18:24\n",
      "\u001b[32m[05/16 13:15:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 1529/2065. 2.0475 s / img. ETA=0:18:18\n",
      "\u001b[32m[05/16 13:15:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 1532/2065. 2.0475 s / img. ETA=0:18:12\n",
      "\u001b[32m[05/16 13:15:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 1535/2065. 2.0475 s / img. ETA=0:18:06\n",
      "\u001b[32m[05/16 13:15:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 1538/2065. 2.0475 s / img. ETA=0:18:00\n",
      "\u001b[32m[05/16 13:15:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 1541/2065. 2.0475 s / img. ETA=0:17:54\n",
      "\u001b[32m[05/16 13:15:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 1544/2065. 2.0475 s / img. ETA=0:17:47\n",
      "\u001b[32m[05/16 13:15:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 1547/2065. 2.0475 s / img. ETA=0:17:41\n",
      "\u001b[32m[05/16 13:16:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 1550/2065. 2.0475 s / img. ETA=0:17:35\n",
      "\u001b[32m[05/16 13:16:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 1553/2065. 2.0475 s / img. ETA=0:17:29\n",
      "\u001b[32m[05/16 13:16:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 1556/2065. 2.0475 s / img. ETA=0:17:23\n",
      "\u001b[32m[05/16 13:16:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 1559/2065. 2.0475 s / img. ETA=0:17:17\n",
      "\u001b[32m[05/16 13:16:28 d2.evaluation.evaluator:197]: \u001b[0mInference done 1562/2065. 2.0475 s / img. ETA=0:17:11\n",
      "\u001b[32m[05/16 13:16:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 1565/2065. 2.0475 s / img. ETA=0:17:04\n",
      "\u001b[32m[05/16 13:16:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 1568/2065. 2.0475 s / img. ETA=0:16:58\n",
      "\u001b[32m[05/16 13:16:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 1571/2065. 2.0475 s / img. ETA=0:16:52\n",
      "\u001b[32m[05/16 13:16:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 1574/2065. 2.0475 s / img. ETA=0:16:46\n",
      "\u001b[32m[05/16 13:16:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 1577/2065. 2.0475 s / img. ETA=0:16:40\n",
      "\u001b[32m[05/16 13:17:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 1580/2065. 2.0475 s / img. ETA=0:16:34\n",
      "\u001b[32m[05/16 13:17:11 d2.evaluation.evaluator:197]: \u001b[0mInference done 1583/2065. 2.0475 s / img. ETA=0:16:28\n",
      "\u001b[32m[05/16 13:17:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 1586/2065. 2.0475 s / img. ETA=0:16:21\n",
      "\u001b[32m[05/16 13:17:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 1589/2065. 2.0475 s / img. ETA=0:16:15\n",
      "\u001b[32m[05/16 13:17:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 1592/2065. 2.0475 s / img. ETA=0:16:09\n",
      "\u001b[32m[05/16 13:17:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 1595/2065. 2.0475 s / img. ETA=0:16:03\n",
      "\u001b[32m[05/16 13:17:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 1598/2065. 2.0475 s / img. ETA=0:15:57\n",
      "\u001b[32m[05/16 13:17:48 d2.evaluation.evaluator:197]: \u001b[0mInference done 1601/2065. 2.0475 s / img. ETA=0:15:51\n",
      "\u001b[32m[05/16 13:17:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 1604/2065. 2.0475 s / img. ETA=0:15:44\n",
      "\u001b[32m[05/16 13:18:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 1607/2065. 2.0475 s / img. ETA=0:15:38\n",
      "\u001b[32m[05/16 13:18:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 1610/2065. 2.0475 s / img. ETA=0:15:32\n",
      "\u001b[32m[05/16 13:18:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 1613/2065. 2.0475 s / img. ETA=0:15:26\n",
      "\u001b[32m[05/16 13:18:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 1616/2065. 2.0475 s / img. ETA=0:15:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 13:18:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 1619/2065. 2.0475 s / img. ETA=0:15:14\n",
      "\u001b[32m[05/16 13:18:31 d2.evaluation.evaluator:197]: \u001b[0mInference done 1622/2065. 2.0475 s / img. ETA=0:15:08\n",
      "\u001b[32m[05/16 13:18:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 1625/2065. 2.0475 s / img. ETA=0:15:01\n",
      "\u001b[32m[05/16 13:18:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 1628/2065. 2.0475 s / img. ETA=0:14:55\n",
      "\u001b[32m[05/16 13:18:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 1631/2065. 2.0475 s / img. ETA=0:14:49\n",
      "\u001b[32m[05/16 13:18:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 1634/2065. 2.0475 s / img. ETA=0:14:43\n",
      "\u001b[32m[05/16 13:19:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 1637/2065. 2.0475 s / img. ETA=0:14:37\n",
      "\u001b[32m[05/16 13:19:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 1640/2065. 2.0475 s / img. ETA=0:14:31\n",
      "\u001b[32m[05/16 13:19:14 d2.evaluation.evaluator:197]: \u001b[0mInference done 1643/2065. 2.0475 s / img. ETA=0:14:25\n",
      "\u001b[32m[05/16 13:19:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 1646/2065. 2.0475 s / img. ETA=0:14:18\n",
      "\u001b[32m[05/16 13:19:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 1649/2065. 2.0475 s / img. ETA=0:14:12\n",
      "\u001b[32m[05/16 13:19:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 1652/2065. 2.0475 s / img. ETA=0:14:06\n",
      "\u001b[32m[05/16 13:19:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 1655/2065. 2.0475 s / img. ETA=0:14:00\n",
      "\u001b[32m[05/16 13:19:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 1658/2065. 2.0475 s / img. ETA=0:13:54\n",
      "\u001b[32m[05/16 13:19:51 d2.evaluation.evaluator:197]: \u001b[0mInference done 1661/2065. 2.0475 s / img. ETA=0:13:48\n",
      "\u001b[32m[05/16 13:19:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 1664/2065. 2.0475 s / img. ETA=0:13:41\n",
      "\u001b[32m[05/16 13:20:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 1667/2065. 2.0475 s / img. ETA=0:13:35\n",
      "\u001b[32m[05/16 13:20:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 1670/2065. 2.0475 s / img. ETA=0:13:29\n",
      "\u001b[32m[05/16 13:20:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 1673/2065. 2.0475 s / img. ETA=0:13:23\n",
      "\u001b[32m[05/16 13:20:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 1676/2065. 2.0475 s / img. ETA=0:13:17\n",
      "\u001b[32m[05/16 13:20:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 1679/2065. 2.0475 s / img. ETA=0:13:11\n",
      "\u001b[32m[05/16 13:20:34 d2.evaluation.evaluator:197]: \u001b[0mInference done 1682/2065. 2.0475 s / img. ETA=0:13:05\n",
      "\u001b[32m[05/16 13:20:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 1685/2065. 2.0476 s / img. ETA=0:12:58\n",
      "\u001b[32m[05/16 13:20:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 1688/2065. 2.0476 s / img. ETA=0:12:52\n",
      "\u001b[32m[05/16 13:20:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 1691/2065. 2.0476 s / img. ETA=0:12:46\n",
      "\u001b[32m[05/16 13:20:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 1694/2065. 2.0476 s / img. ETA=0:12:40\n",
      "\u001b[32m[05/16 13:21:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 1697/2065. 2.0476 s / img. ETA=0:12:34\n",
      "\u001b[32m[05/16 13:21:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 1700/2065. 2.0475 s / img. ETA=0:12:28\n",
      "\u001b[32m[05/16 13:21:17 d2.evaluation.evaluator:197]: \u001b[0mInference done 1703/2065. 2.0475 s / img. ETA=0:12:22\n",
      "\u001b[32m[05/16 13:21:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 1706/2065. 2.0475 s / img. ETA=0:12:15\n",
      "\u001b[32m[05/16 13:21:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 1709/2065. 2.0476 s / img. ETA=0:12:09\n",
      "\u001b[32m[05/16 13:21:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 1712/2065. 2.0476 s / img. ETA=0:12:03\n",
      "\u001b[32m[05/16 13:21:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 1715/2065. 2.0476 s / img. ETA=0:11:57\n",
      "\u001b[32m[05/16 13:21:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 1718/2065. 2.0476 s / img. ETA=0:11:51\n",
      "\u001b[32m[05/16 13:21:54 d2.evaluation.evaluator:197]: \u001b[0mInference done 1721/2065. 2.0476 s / img. ETA=0:11:45\n",
      "\u001b[32m[05/16 13:22:00 d2.evaluation.evaluator:197]: \u001b[0mInference done 1724/2065. 2.0476 s / img. ETA=0:11:39\n",
      "\u001b[32m[05/16 13:22:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 1727/2065. 2.0475 s / img. ETA=0:11:32\n",
      "\u001b[32m[05/16 13:22:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 1730/2065. 2.0475 s / img. ETA=0:11:26\n",
      "\u001b[32m[05/16 13:22:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 1733/2065. 2.0475 s / img. ETA=0:11:20\n",
      "\u001b[32m[05/16 13:22:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 1736/2065. 2.0475 s / img. ETA=0:11:14\n",
      "\u001b[32m[05/16 13:22:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 1739/2065. 2.0475 s / img. ETA=0:11:08\n",
      "\u001b[32m[05/16 13:22:37 d2.evaluation.evaluator:197]: \u001b[0mInference done 1742/2065. 2.0475 s / img. ETA=0:11:02\n",
      "\u001b[32m[05/16 13:22:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 1745/2065. 2.0476 s / img. ETA=0:10:55\n",
      "\u001b[32m[05/16 13:22:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 1748/2065. 2.0476 s / img. ETA=0:10:49\n",
      "\u001b[32m[05/16 13:22:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 1751/2065. 2.0475 s / img. ETA=0:10:43\n",
      "\u001b[32m[05/16 13:23:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 1754/2065. 2.0475 s / img. ETA=0:10:37\n",
      "\u001b[32m[05/16 13:23:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 1757/2065. 2.0476 s / img. ETA=0:10:31\n",
      "\u001b[32m[05/16 13:23:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 1760/2065. 2.0475 s / img. ETA=0:10:25\n",
      "\u001b[32m[05/16 13:23:20 d2.evaluation.evaluator:197]: \u001b[0mInference done 1763/2065. 2.0476 s / img. ETA=0:10:19\n",
      "\u001b[32m[05/16 13:23:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 1766/2065. 2.0475 s / img. ETA=0:10:12\n",
      "\u001b[32m[05/16 13:23:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 1769/2065. 2.0476 s / img. ETA=0:10:06\n",
      "\u001b[32m[05/16 13:23:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 1772/2065. 2.0476 s / img. ETA=0:10:00\n",
      "\u001b[32m[05/16 13:23:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 1775/2065. 2.0476 s / img. ETA=0:09:54\n",
      "\u001b[32m[05/16 13:23:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 1778/2065. 2.0476 s / img. ETA=0:09:48\n",
      "\u001b[32m[05/16 13:23:57 d2.evaluation.evaluator:197]: \u001b[0mInference done 1781/2065. 2.0475 s / img. ETA=0:09:42\n",
      "\u001b[32m[05/16 13:24:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 1784/2065. 2.0475 s / img. ETA=0:09:36\n",
      "\u001b[32m[05/16 13:24:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 1787/2065. 2.0475 s / img. ETA=0:09:29\n",
      "\u001b[32m[05/16 13:24:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 1790/2065. 2.0475 s / img. ETA=0:09:23\n",
      "\u001b[32m[05/16 13:24:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 1793/2065. 2.0475 s / img. ETA=0:09:17\n",
      "\u001b[32m[05/16 13:24:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 1796/2065. 2.0475 s / img. ETA=0:09:11\n",
      "\u001b[32m[05/16 13:24:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 1799/2065. 2.0475 s / img. ETA=0:09:05\n",
      "\u001b[32m[05/16 13:24:40 d2.evaluation.evaluator:197]: \u001b[0mInference done 1802/2065. 2.0475 s / img. ETA=0:08:59\n",
      "\u001b[32m[05/16 13:24:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 1805/2065. 2.0476 s / img. ETA=0:08:52\n",
      "\u001b[32m[05/16 13:24:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 1808/2065. 2.0475 s / img. ETA=0:08:46\n",
      "\u001b[32m[05/16 13:24:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 1811/2065. 2.0475 s / img. ETA=0:08:40\n",
      "\u001b[32m[05/16 13:25:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 1814/2065. 2.0475 s / img. ETA=0:08:34\n",
      "\u001b[32m[05/16 13:25:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 1817/2065. 2.0475 s / img. ETA=0:08:28\n",
      "\u001b[32m[05/16 13:25:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 1820/2065. 2.0475 s / img. ETA=0:08:22\n",
      "\u001b[32m[05/16 13:25:23 d2.evaluation.evaluator:197]: \u001b[0mInference done 1823/2065. 2.0475 s / img. ETA=0:08:16\n",
      "\u001b[32m[05/16 13:25:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 1826/2065. 2.0475 s / img. ETA=0:08:09\n",
      "\u001b[32m[05/16 13:25:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 1829/2065. 2.0475 s / img. ETA=0:08:03\n",
      "\u001b[32m[05/16 13:25:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 1832/2065. 2.0475 s / img. ETA=0:07:57\n",
      "\u001b[32m[05/16 13:25:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 1835/2065. 2.0475 s / img. ETA=0:07:51\n",
      "\u001b[32m[05/16 13:25:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 1838/2065. 2.0475 s / img. ETA=0:07:45\n",
      "\u001b[32m[05/16 13:25:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 1841/2065. 2.0475 s / img. ETA=0:07:39\n",
      "\u001b[32m[05/16 13:26:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 1844/2065. 2.0475 s / img. ETA=0:07:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 13:26:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 1847/2065. 2.0475 s / img. ETA=0:07:26\n",
      "\u001b[32m[05/16 13:26:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 1850/2065. 2.0475 s / img. ETA=0:07:20\n",
      "\u001b[32m[05/16 13:26:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 1853/2065. 2.0475 s / img. ETA=0:07:14\n",
      "\u001b[32m[05/16 13:26:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 1856/2065. 2.0475 s / img. ETA=0:07:08\n",
      "\u001b[32m[05/16 13:26:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 1859/2065. 2.0475 s / img. ETA=0:07:02\n",
      "\u001b[32m[05/16 13:26:43 d2.evaluation.evaluator:197]: \u001b[0mInference done 1862/2065. 2.0475 s / img. ETA=0:06:56\n",
      "\u001b[32m[05/16 13:26:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 1865/2065. 2.0476 s / img. ETA=0:06:49\n",
      "\u001b[32m[05/16 13:26:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 1868/2065. 2.0475 s / img. ETA=0:06:43\n",
      "\u001b[32m[05/16 13:27:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 1871/2065. 2.0475 s / img. ETA=0:06:37\n",
      "\u001b[32m[05/16 13:27:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 1874/2065. 2.0475 s / img. ETA=0:06:31\n",
      "\u001b[32m[05/16 13:27:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 1877/2065. 2.0475 s / img. ETA=0:06:25\n",
      "\u001b[32m[05/16 13:27:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 1880/2065. 2.0475 s / img. ETA=0:06:19\n",
      "\u001b[32m[05/16 13:27:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 1883/2065. 2.0475 s / img. ETA=0:06:13\n",
      "\u001b[32m[05/16 13:27:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 1886/2065. 2.0475 s / img. ETA=0:06:06\n",
      "\u001b[32m[05/16 13:27:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 1889/2065. 2.0476 s / img. ETA=0:06:00\n",
      "\u001b[32m[05/16 13:27:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 1892/2065. 2.0475 s / img. ETA=0:05:54\n",
      "\u001b[32m[05/16 13:27:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 1895/2065. 2.0475 s / img. ETA=0:05:48\n",
      "\u001b[32m[05/16 13:27:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 1898/2065. 2.0475 s / img. ETA=0:05:42\n",
      "\u001b[32m[05/16 13:28:03 d2.evaluation.evaluator:197]: \u001b[0mInference done 1901/2065. 2.0476 s / img. ETA=0:05:36\n",
      "\u001b[32m[05/16 13:28:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 1904/2065. 2.0476 s / img. ETA=0:05:30\n",
      "\u001b[32m[05/16 13:28:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 1907/2065. 2.0476 s / img. ETA=0:05:23\n",
      "\u001b[32m[05/16 13:28:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 1910/2065. 2.0476 s / img. ETA=0:05:17\n",
      "\u001b[32m[05/16 13:28:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 1913/2065. 2.0476 s / img. ETA=0:05:11\n",
      "\u001b[32m[05/16 13:28:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 1916/2065. 2.0476 s / img. ETA=0:05:05\n",
      "\u001b[32m[05/16 13:28:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 1919/2065. 2.0475 s / img. ETA=0:04:59\n",
      "\u001b[32m[05/16 13:28:46 d2.evaluation.evaluator:197]: \u001b[0mInference done 1922/2065. 2.0475 s / img. ETA=0:04:53\n",
      "\u001b[32m[05/16 13:28:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 1925/2065. 2.0475 s / img. ETA=0:04:46\n",
      "\u001b[32m[05/16 13:28:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 1928/2065. 2.0476 s / img. ETA=0:04:40\n",
      "\u001b[32m[05/16 13:29:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 1931/2065. 2.0476 s / img. ETA=0:04:34\n",
      "\u001b[32m[05/16 13:29:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 1934/2065. 2.0476 s / img. ETA=0:04:28\n",
      "\u001b[32m[05/16 13:29:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 1937/2065. 2.0476 s / img. ETA=0:04:22\n",
      "\u001b[32m[05/16 13:29:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 1940/2065. 2.0476 s / img. ETA=0:04:16\n",
      "\u001b[32m[05/16 13:29:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 1943/2065. 2.0476 s / img. ETA=0:04:10\n",
      "\u001b[32m[05/16 13:29:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 1946/2065. 2.0476 s / img. ETA=0:04:03\n",
      "\u001b[32m[05/16 13:29:41 d2.evaluation.evaluator:197]: \u001b[0mInference done 1949/2065. 2.0476 s / img. ETA=0:03:57\n",
      "\u001b[32m[05/16 13:29:47 d2.evaluation.evaluator:197]: \u001b[0mInference done 1952/2065. 2.0476 s / img. ETA=0:03:51\n",
      "\u001b[32m[05/16 13:29:53 d2.evaluation.evaluator:197]: \u001b[0mInference done 1955/2065. 2.0476 s / img. ETA=0:03:45\n",
      "\u001b[32m[05/16 13:29:59 d2.evaluation.evaluator:197]: \u001b[0mInference done 1958/2065. 2.0476 s / img. ETA=0:03:39\n",
      "\u001b[32m[05/16 13:30:06 d2.evaluation.evaluator:197]: \u001b[0mInference done 1961/2065. 2.0476 s / img. ETA=0:03:33\n",
      "\u001b[32m[05/16 13:30:12 d2.evaluation.evaluator:197]: \u001b[0mInference done 1964/2065. 2.0476 s / img. ETA=0:03:27\n",
      "\u001b[32m[05/16 13:30:18 d2.evaluation.evaluator:197]: \u001b[0mInference done 1967/2065. 2.0476 s / img. ETA=0:03:20\n",
      "\u001b[32m[05/16 13:30:24 d2.evaluation.evaluator:197]: \u001b[0mInference done 1970/2065. 2.0476 s / img. ETA=0:03:14\n",
      "\u001b[32m[05/16 13:30:30 d2.evaluation.evaluator:197]: \u001b[0mInference done 1973/2065. 2.0476 s / img. ETA=0:03:08\n",
      "\u001b[32m[05/16 13:30:36 d2.evaluation.evaluator:197]: \u001b[0mInference done 1976/2065. 2.0476 s / img. ETA=0:03:02\n",
      "\u001b[32m[05/16 13:30:42 d2.evaluation.evaluator:197]: \u001b[0mInference done 1979/2065. 2.0476 s / img. ETA=0:02:56\n",
      "\u001b[32m[05/16 13:30:49 d2.evaluation.evaluator:197]: \u001b[0mInference done 1982/2065. 2.0476 s / img. ETA=0:02:50\n",
      "\u001b[32m[05/16 13:30:55 d2.evaluation.evaluator:197]: \u001b[0mInference done 1985/2065. 2.0476 s / img. ETA=0:02:43\n",
      "\u001b[32m[05/16 13:31:01 d2.evaluation.evaluator:197]: \u001b[0mInference done 1988/2065. 2.0476 s / img. ETA=0:02:37\n",
      "\u001b[32m[05/16 13:31:07 d2.evaluation.evaluator:197]: \u001b[0mInference done 1991/2065. 2.0476 s / img. ETA=0:02:31\n",
      "\u001b[32m[05/16 13:31:13 d2.evaluation.evaluator:197]: \u001b[0mInference done 1994/2065. 2.0476 s / img. ETA=0:02:25\n",
      "\u001b[32m[05/16 13:31:19 d2.evaluation.evaluator:197]: \u001b[0mInference done 1997/2065. 2.0476 s / img. ETA=0:02:19\n",
      "\u001b[32m[05/16 13:31:26 d2.evaluation.evaluator:197]: \u001b[0mInference done 2000/2065. 2.0476 s / img. ETA=0:02:13\n",
      "\u001b[32m[05/16 13:31:32 d2.evaluation.evaluator:197]: \u001b[0mInference done 2003/2065. 2.0476 s / img. ETA=0:02:07\n",
      "\u001b[32m[05/16 13:31:38 d2.evaluation.evaluator:197]: \u001b[0mInference done 2006/2065. 2.0476 s / img. ETA=0:02:00\n",
      "\u001b[32m[05/16 13:31:44 d2.evaluation.evaluator:197]: \u001b[0mInference done 2009/2065. 2.0476 s / img. ETA=0:01:54\n",
      "\u001b[32m[05/16 13:31:50 d2.evaluation.evaluator:197]: \u001b[0mInference done 2012/2065. 2.0476 s / img. ETA=0:01:48\n",
      "\u001b[32m[05/16 13:31:56 d2.evaluation.evaluator:197]: \u001b[0mInference done 2015/2065. 2.0476 s / img. ETA=0:01:42\n",
      "\u001b[32m[05/16 13:32:02 d2.evaluation.evaluator:197]: \u001b[0mInference done 2018/2065. 2.0476 s / img. ETA=0:01:36\n",
      "\u001b[32m[05/16 13:32:09 d2.evaluation.evaluator:197]: \u001b[0mInference done 2021/2065. 2.0476 s / img. ETA=0:01:30\n",
      "\u001b[32m[05/16 13:32:15 d2.evaluation.evaluator:197]: \u001b[0mInference done 2024/2065. 2.0476 s / img. ETA=0:01:24\n",
      "\u001b[32m[05/16 13:32:21 d2.evaluation.evaluator:197]: \u001b[0mInference done 2027/2065. 2.0476 s / img. ETA=0:01:17\n",
      "\u001b[32m[05/16 13:32:27 d2.evaluation.evaluator:197]: \u001b[0mInference done 2030/2065. 2.0476 s / img. ETA=0:01:11\n",
      "\u001b[32m[05/16 13:32:33 d2.evaluation.evaluator:197]: \u001b[0mInference done 2033/2065. 2.0476 s / img. ETA=0:01:05\n",
      "\u001b[32m[05/16 13:32:39 d2.evaluation.evaluator:197]: \u001b[0mInference done 2036/2065. 2.0476 s / img. ETA=0:00:59\n",
      "\u001b[32m[05/16 13:32:45 d2.evaluation.evaluator:197]: \u001b[0mInference done 2039/2065. 2.0476 s / img. ETA=0:00:53\n",
      "\u001b[32m[05/16 13:32:52 d2.evaluation.evaluator:197]: \u001b[0mInference done 2042/2065. 2.0476 s / img. ETA=0:00:47\n",
      "\u001b[32m[05/16 13:32:58 d2.evaluation.evaluator:197]: \u001b[0mInference done 2045/2065. 2.0476 s / img. ETA=0:00:40\n",
      "\u001b[32m[05/16 13:33:04 d2.evaluation.evaluator:197]: \u001b[0mInference done 2048/2065. 2.0476 s / img. ETA=0:00:34\n",
      "\u001b[32m[05/16 13:33:10 d2.evaluation.evaluator:197]: \u001b[0mInference done 2051/2065. 2.0476 s / img. ETA=0:00:28\n",
      "\u001b[32m[05/16 13:33:16 d2.evaluation.evaluator:197]: \u001b[0mInference done 2054/2065. 2.0476 s / img. ETA=0:00:22\n",
      "\u001b[32m[05/16 13:33:22 d2.evaluation.evaluator:197]: \u001b[0mInference done 2057/2065. 2.0476 s / img. ETA=0:00:16\n",
      "\u001b[32m[05/16 13:33:29 d2.evaluation.evaluator:197]: \u001b[0mInference done 2060/2065. 2.0476 s / img. ETA=0:00:10\n",
      "\u001b[32m[05/16 13:33:35 d2.evaluation.evaluator:197]: \u001b[0mInference done 2063/2065. 2.0476 s / img. ETA=0:00:04\n",
      "\u001b[32m[05/16 13:33:39 d2.evaluation.evaluator:166]: \u001b[0mTotal inference time: 1:10:22.847425 (2.049926 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/16 13:33:39 d2.evaluation.evaluator:172]: \u001b[0mTotal inference pure compute time: 1:10:18 (2.047604 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/16 13:33:39 d2.evaluation.pascal_voc_evaluation:81]: \u001b[0mEvaluating voc_2012_test using 2012 metric. Note that results do not use the official Matlab API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/16 13:34:36 d2.engine.defaults:505]: \u001b[0mEvaluation results for voc_2012_test in csv format:\r\n",
      "\u001b[32m[05/16 13:34:36 d2.evaluation.testing:23]: \u001b[0mcopypaste: Task: bbox\r\n",
      "\u001b[32m[05/16 13:34:36 d2.evaluation.testing:24]: \u001b[0mcopypaste: AP,AP50,AP75\r\n",
      "\u001b[32m[05/16 13:34:36 d2.evaluation.testing:25]: \u001b[0mcopypaste: 6.5513,16.4585,4.2806\r\n",
      "\u001b[32m[05/16 13:34:36 d2.utils.events:215]: \u001b[0m eta: 0:00:01  iter: 1999  total_loss: 0.905  loss_cls: 0.261  loss_box_reg: 0.560  loss_rpn_cls: 0.036  loss_rpn_loc: 0.029  time: 1.7627  data_time: 0.0060  lr: 0.001000  max_mem: 2422M\r\n",
      "\u001b[32m[05/16 13:34:36 d2.engine.hooks:118]: \u001b[0mOverall training speed: 1997 iterations in 0:58:41 (1.7636 s / it)\r\n",
      "\u001b[32m[05/16 13:34:36 d2.engine.hooks:125]: \u001b[0mTotal training time: 2:10:15 (1:11:33 on hooks)\r\n"
     ]
    }
   ],
   "source": [
    "# RCNN has c4/fpn, I don't know the diff yet\n",
    "# https://github.com/facebookresearch/detectron2/tree/master/configs/PascalVOC-Detection\n",
    "!rm detectron2-ResNeSt/datasets/VOC2012\n",
    "!ln -s `pwd`/kitti-voc/VOC2012 detectron2-ResNeSt/datasets/VOC2012\n",
    "!cp lsi-faster-rcnn/data/kitti/lists/train_lsi.txt detectron2-ResNeSt/datasets/VOC2012/ImageSets/Main/trainval.txt\n",
    "!cp lsi-faster-rcnn/data/kitti/lists/val_lsi.txt detectron2-ResNeSt/datasets/VOC2012/ImageSets/Main/test.txt\n",
    "\n",
    "# Only use a few test data\n",
    "# !head -n 10 lsi-faster-rcnn/data/kitti/lists/val_lsi.txt > detectron2-ResNeSt/datasets/VOC2012/ImageSets/Main/test.txt\n",
    "\n",
    "# !(cd detectron2-ResNeSt/ && python3 tools/train_net.py --eval-only  \\\n",
    "!(cd detectron2-ResNeSt/ && python3 tools/train_net.py \\\n",
    "--config-file configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
